<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Le Blog d'Eric Vidal]]></title>
  <link href="http://evidal.github.io/atom.xml" rel="self"/>
  <link href="http://evidal.github.io/"/>
  <updated>2015-01-12T22:02:09+01:00</updated>
  <id>http://evidal.github.io/</id>
  <author>
    <name><![CDATA[Eric Vidal]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[MOOC Machine Learning par Andrew Ng]]></title>
    <link href="http://evidal.github.io/blog/2014/12/23/mooc-machine-learning/"/>
    <updated>2014-12-23T00:00:00+01:00</updated>
    <id>http://evidal.github.io/blog/2014/12/23/mooc-machine-learning</id>
    <content type="html"><![CDATA[<p>Ca y&#8217;est, c&#8217;est fait. Je viens de terminer le MOOC <a href="https://www.coursera.org/course/ml">Machine Learning</a> donnée par <a href="http://cs.stanford.edu/people/ang/">Andrew Ng</a> de l&#8217;université de Stanford. Je suis d&#8217;autant plus content que ce MOOC, n&#8217;est pas un petit. Il dure 10 semaines avec environ 5-7 heures de travail par semaine. J&#8217;avais déjà fait 2 tentatives sur un autre sujet, mais j&#8217;avais arrêté au premier tiers à chaque fois par manque de temps. En effet toutes les semaines il faut rendre un exercice de programmation et répondre à un ou plusieurs QCM. Si on rend ses devoirs en retard, on est pénalisé de 20%. Et pour être &ldquo;dîplomé&rdquo;, il faut obtenir au moins 80% de réussite. Bref, si vous voulez suivre un MOOC, il faut se dégager du temps et être régulier dans son travail, sous peine de perdre le fil.</p>

<p>Le cours balayait les méthodes de base du machine learning avec à chaque fois une application pratique:</p>

<ul>
<li><strong>régression linéaire</strong>, pour prédire une variable en fonction de plusieurs entrées</li>
<li>rappel d&#8217;<strong>algèbre linéaire</strong>, pour revoir toutes les maths associées aux matrices et aux vecteurs</li>
<li><strong>régression linaire</strong> avec plusieurs variables, pour predire plusieurs variables en fonction de plusieurs entrées</li>
<li><strong>régression logistique</strong>, classification sur une ou plusieurs classes et normalisation des données (avec en application un OCR !)</li>
<li><strong>réseau neuronaux</strong> (toujours l&#8217;OCR en application)</li>
<li><strong>conseils pratiques</strong> pour la mise en oeuvre des algorithmes de Machine Learning : Comment développer, débugger, structurer, tester, etc&hellip;</li>
<li><strong>Machine à vecteurs de support (SVMs)</strong>, un algorithme encore plus puissant de classification</li>
<li>Apprentissage non supervisé: <strong>clustering</strong>, pour former des groupes d&#8217;éléments se ressemblant</li>
<li><strong>Réduction dimensionnelle</strong> pour notamment la visualisation des données</li>
<li><strong>Détection d&#8217;anomalies</strong></li>
<li><strong>Système de recommandations</strong> qui est en fait le résultat de plusieurs classifications faite à grand échelle</li>
<li>Machine Learning sur des <strong>gros volumes de données</strong> (Big Data)</li>
<li>Présentation d&#8217;une application complète de Machine Learning (plusieurs algorithmes enchainés pour effectuer une tâche)</li>
</ul>


<p>Au niveau de la plate-forme, <a href="https://www.coursera.org">Coursera</a> est un site très bien fait. La recherche de cours est efficace et les sujets sont assez variés. Les cours sont présentés à travers de petites vidéos d&#8217;introduction et d&#8217;un résumé des sujets abordés.</p>

<p>Une fois inscrit à un cours, on accède à une page dédiée à celui-ci. Cette page est mise à jour toutes les semaines avec l&#8217;ajout des vidéos du cours de la semaine et parfois de news. Ces vidéos montrent le professeur et un support de cours. Le professeur dispose d&#8217;un crayon avec lequel il peut annoter le support du cours, ce qui rend sa présentation plus vivante. De plus les vidéos sont parfois agrémentées de QCM (ne comptant pas dans la note finale) permettant de vérifier que l&#8217;on comprend bien le cours. Les vidéos et les supports sont disponibles en téléchargement pour une utilisation off-line, ce qui est pratique quand on est en déplacement.</p>

<p>Chaque semaine des devoirs doivent être rendu. Que ce soit un QCM ou un exercice de programmation, les résultats sont connus immédiatement. On peut soumettre un devoir autant de fois que l&#8217;on veut, ce qui permet de viser à chaque fois un score parfait. Des dispositifs sont en place pour éviter la soumission de devoir en force brute, ainsi chaque tentative de QCM doit être espacée d&#8217;au moins 10 minutes et de 5 minutes pour les exercices de programmation.</p>

<p>Les exercices de programmation utilisait <a href="https://www.gnu.org/software/octave/">Octave</a> une version GNU de <a href="http://fr.mathworks.com/products/matlab/index.html?ref=nn_matlab">Matlab</a>. Chaque semaine il fallait télécharger une archive contenant un code source incomplet et des instructions en PDF pour le compléter. Le code source contenait également de quoi soumettre l&#8217;exercice en ligne.</p>

<p>Enfin un forum et un chanel IRC était disponible pour socialiser pendant le cours ou poser des questions à l&#8217;équipe pédagogique.</p>

<p>Bref que ce soit au niveau contenu ou niveau de la forme, c&#8217;était un vrai plaisir de suivre ce cours et une fierté d&#8217;être allé au bout.
Je vous conseille vivement de participer à une des prochaines sessions.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction &agrave; Hadoop]]></title>
    <link href="http://evidal.github.io/blog/2014/06/23/hadoop-big-data/"/>
    <updated>2014-06-23T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2014/06/23/hadoop-big-data</id>
    <content type="html"><![CDATA[<p><a href="http://hadoop.apache.org/">Hadoop</a> est un système permettant de gérer des très gros volumes de données aussi bien au niveau de leur
stockage qu&#8217;au niveau de leur traitement. Pour mettre les choses au clair tout de suite, Hadoop est une solution à oublier en
dessous d&#8217;une grosse dizaine de serveurs. Hadoop est un système taillé pour gérer des centaines voir des milliers de serveurs. Il faut donc dégainer cette solution quand c&#8217;est nécéssaire. Google utilise par exemple ce type de technologie pour gérer les gros
traitements sur son cluster de serveurs. C&#8217;est d&#8217;ailleurs Google qui est à l&#8217;origine des concepts fondateurs d&#8217;Hadoop.</p>

<!--more-->


<p>Hadoop n&#8217;est pas monobloc, c&#8217;est plutot un ensemble de composants spécialisés.</p>

<h1>HDFS</h1>

<p>Hadoop Distributed File System (HDFS) est l&#8217;implémentation open source des concepts introduits par le Google File System.
C&#8217;est un système de fichier ditribué, taillé pour les gros volumes de données. HDFS est capable de gérer des volumes de
plusieurs péta octets. Les blocs de données sont proportionnelles à la volumétrie potentielle et sont fixés par défaut à
64 méga octets.</p>

<p><img src="http://evidal.github.io/images/posts/2014-06-15-hadoop-big-data/hdfsarchitecture.gif" alt="HDFS Architecture" />
(source <a href="http://hadoop.apache.org/docs/r1.2.1/hdfs_design.html">http://hadoop.apache.org/docs/r1.2.1/hdfs_design.html</a>)</p>

<p>Le Namenode est le serveur du cluster Hadoop s&#8217;occupant des méta-données du file system (Nom, réplication, emplacement, etc&hellip;)</p>

<p>Les serveurs de données eux stockent les blocs des fichiers.</p>

<h1>Map Reduce</h1>

<p>Map Reduce est un modèle de programmation permettant de distribuer l&#8217;éxécution d&#8217;une tache sur plusieurs serveurs (e.g. un tri, une
indexation, un calcul, etc.) Le &ldquo;travail&rdquo; de Map Reduce va être de découper, trier et rassembler les données à différents moment de
l&#8217;éxécution d&#8217;une tâche.</p>

<p>On peut schématiser l&#8217;éxection d&#8217;un batch Map Reduce avec le schéma suivant:</p>

<p><img src="http://evidal.github.io/images/posts/2014-06-15-hadoop-big-data/MapReduce.png" alt="HDFS Architecture" /></p>

<ul>
<li>Les données stockées dans des blocs HDFS vont être tronçonnées en InputSplit.

<ul>
<li>e.g. des lignes d&#8217;un fichier de log</li>
</ul>
</li>
<li>Les records readers vont assigner une clé k1 et une valeur v1 pour toute donnée lue.

<ul>
<li>e.g. le numéro de la ligne comme clé, la ligne compléte en valeur</li>
</ul>
</li>
<li>Le fonction de Mapping va lire et transformer cette première entrée en une autre paire clé-valeur (k2, v2).

<ul>
<li>e.g. La ligne de log est analysée, on met en clé le nom d&#8217;un utilisateur et en valeur 1, représentant un login par exemple</li>
</ul>
</li>
<li>La fonction de partition va déterminer en fonction de la clé k2 vers quel Reducer la clé va être routée</li>
<li>La fonction de Shuffle and Sort rassemble par clé k2 toutes les valeurs v2 émises pas les Mappers

<ul>
<li>e.g. On se retrouve à cette étape avec le nom d&#8217;un utilisateur et une liste de 1 correspondant à toutes les occurences de connections</li>
</ul>
</li>
<li>Le Reducer va transformer une clé k2 et sa liste de valeur v2 en une nouvelle clé k3 et une nouvelle valeur v3.

<ul>
<li>e.g. Le reducer va sommer toutes les valeurs pour un utilisateur en comptant toutes les valeurs de la liste. Par exemple evidal c&#8217;est connecté 3 fois.</li>
</ul>
</li>
<li>Le traitement étant terminé, on peut procéder à l&#8217;écriture des fichiers.</li>
</ul>


<p>Implémentez un job Map Reduce pour Hadoop consiste en l&#8217;assemblage de Mapper, Reducer, Reader, Writer, Partionner.</p>

<p>Des implémentations de certaines de ces classes sont déjà fournies pour des tâches simples (e.g. identités).</p>

<p>L&#8217;assemblage se fait via une une classe Java qui va positionner via des setters les éléménts à utiliser.
On livre sur le cluster un jar contenant les classes nécéssaires à l&#8217;éxécution d&#8217;un job.</p>

<p>Pour l&#8217;éxécution, Hadoop va instancier une JVM sur les différents noeuds et éxécuter le job qu&#8217;on a livré.<br/>
En développement, un mode classique (lancé de manière transparente) permet d&#8217;éxécuter un job Map Reduce en dehors d&#8217;un cluster Hadoop.<br/>
Pour les test unitaire, on peut utiliser des outils comme <a href="http://mrunit.apache.org/">MRUnit</a>.</p>

<h1>Hive, Impala, Pig &amp; Oozie</h1>

<p>Map Reduce, c&#8217;est bien mais ça peut devenir un peu fastidieux s&#8217;il faut écrire des jointures. D&#8217;autant plus que ce n&#8217;est pas vraiment passionnant à coder. Des outils de plus haut niveau ont été développés pour travailler plus facilement qu&#8217;avec Map Reduce.</p>

<ul>
<li><a href="http://hive.apache.org/">Hive</a> est un langage très similaire au SQL. Tout d&#8217;abord on mappe les données d&#8217;un fichier pour exposer son contenu comme une table. Une fois que l&#8217;on a déclaré plusieurs tables, on peut écrire des requêtes pour interroger le cluster Hadoop comme un base de données relationnelle. Ca semble trivial, mais il faut toujours penser que ce système est fait pour gérer de très gros volumes de données, pas des volumétries standards.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SELECT stock.product, SUM(orders.purchases)
</span><span class='line'>FROM stock JOIN orders
</span><span class='line'>ON (stock.id = orders.stock_id)
</span><span class='line'>WHERE orders.quarter = 'Q1'
</span><span class='line'>GROUP BY stock.product;</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://pig.apache.org/">Pig</a> est un autre système permettant d&#8217;écrire des jobs Map Reduce de manière plus simple. Pig prend plus la forme d&#8217;un script, on indique quelles données charger et les opérations à faire avec.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>stock = LOAD '/user/fred/stock' AS (id, item);
</span><span class='line'>orders = LOAD '/user/fred/orders' AS (id, cost);
</span><span class='line'>grpd = GROUP orders BY id;
</span><span class='line'>totals = FOREACH grpd GENERATE group,
</span><span class='line'>SUM(orders.cost) AS t;
</span><span class='line'>result = JOIN stock BY id, totals BY group;
</span><span class='line'>DUMP result;</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html">Impala</a> ressemble à Hive du point de vue syntaxique. La grosse différence entre les 2 est qu&#8217;Impala ne va pas générer un job Map Reduce, mais va utiliser d&#8217;autres algorithmes pour éxécuter la requête et donner une réponse très rapidement.</li>
</ul>


<p>Oozie est un système permettant d&#8217;écrire plusieurs tâches qui vont s&#8217;enchainer. Par exemlple commencer par un job Hive, suivi d&#8217;un job Map Reduce classique et enfin d&#8217;un autre job Hive. Cela permet de créer des chaines de traitement plus complexes.</p>

<h1>Distribution</h1>

<p>Si Hadoop est disponible sur le site du projet Apache, des distributions sont également disponibles chez des éditeurs:</p>

<ul>
<li><a href="http://www.cloudera.com/content/cloudera/en/home.html">Cloudera</a></li>
<li><a href="Horton%20Works">Horton Works</a></li>
<li><a href="http://www.mapr.com/">MapR</a></li>
</ul>


<p>Le gros avantage de passer par une distribution commerciale est que l&#8217;on peut acheter du support. Parfois, ces distributions assemblent des versions différentes des composants core pour avoir un fonctionnement plus cohérent.</p>

<p>Enfin, sur leurs sites, des machines virtuelles (e.g. chez <a href="http://www.cloudera.com/content/support/en/downloads/quickstart_vms/cdh-5-0-x.html">Cloudera</a>) sont disponibles pour tester, ce qui est un gros gain de temps.</p>

<h1>Conclusion</h1>

<p>Hadoop n&#8217;est pas la solution que l&#8217;on va sortir à tout bout de champ. Le but est de manipuler de très très gros volumes de données.
C&#8217;est clairement un outil qui va devenir de plus en plus utile avec l&#8217;explosion des données récoltées par les objets connectées ou toutes les traces que nous laissons sur Internet.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mix-it 2014]]></title>
    <link href="http://evidal.github.io/blog/2014/05/02/mixit14/"/>
    <updated>2014-05-02T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2014/05/02/mixit14</id>
    <content type="html"><![CDATA[<p>Cette année, pas de vacances, j&#8217;ai donc pu me rendre à <a href="http://www.mix-it.fr/">Mix-It</a>. J&#8217;avais loupé la conférence de l&#8217;an dernier et j&#8217;attendais donc cette édition avec beaucoup d&#8217;impatience. Je vais parler ici des ateliers/sessions que j&#8217;ai bien aimé.</p>

<p><img src="http://evidal.github.io/images/posts/2014-05-02-mixit14/mixit.png" alt="MixIt14" /></p>

<h2>Lightning Talks</h2>

<p>Je les ai trouvés plutôt bons et assez riches en comparaison du temps qui leur était imparti.</p>

<p><a href="http://www.mix-it.fr/lightning/541/es6-en-pratique">ES6 en pratique</a> nous rappelait que Javascript évoluait et que de nouvelles
fonctionnalités étaient disponibles dés maintenant. Une invitation à regarder ce qu&#8217;il se passe au niveau de l&#8217;évolution du
langage.</p>

<p><a href="http://www.mix-it.fr/lightning/544/de-l-architecture-dans-les-css">De l&#8217;architecture dans les CSS</a> nous expliquait comment un site comme <a href="http://www.lesfurets.com/">www.lesfurets.com</a> organisait les CSS avec Grunt.</p>

<p><a href="http://www.mix-it.fr/lightning/543/blogger-chaque-jour-pour-etre-riche-et-celebre">Blogger chaque jour pour être riche et célèbre</a> expliquait la démarche de David Gageot qui s&#8217;était mis à bloguer tous les jours depuis quelques temps. Les slides de sa présentation sont disponibles <a href="http://blog.javabien.net/2014/04/29/lightning-talk-at-mix-it/">ici</a>.</p>

<p><a href="http://www.mix-it.fr/lightning/560/5-apprentissages-pour-le-programmeur-debutant">5 apprentissages pour le programmeur débutant</a> était un rappel pour les programmeurs débutants (ou pas) sur 5 bonnes pratiques. Un petit rappel ne fait jamais de mal. Les slides sont <a href="http://blog.ninja-squad.com/2014/05/02/mix-it-lightning-talk/">ici</a>.</p>

<p><a href="http://www.mix-it.fr/lightning/545/-restful-really-">#Restful, really ?</a> expliquait quelles devaient être les caractéristiques d&#8217;une vraie API REST. Un bon rappel également. Les slides sont <a href="http://fr.slideshare.net/xcarpentier1/restful-really">ici</a>.</p>

<h2>Natural Course of Refactoring – a refactoring work</h2>

<p>Une présentation faite par <a href="https://twitter.com/ms_bnsit_pl">Mariusz Sieraczkiewicz</a>. Le but de sa présentation était de montrer
la démarche pour &ldquo;refactorer&rdquo; son code avec quelques astuces. L&#8217;horaire n&#8217;était pas facile (après déjeuner) mais il a su tenir la
salle notamment avec une comparaison osée (refactoring is like sex). Il donne également des pistes pour trouver quels sont les
portions de code à &ldquo;refactorer&rdquo;. Sa présentation est <a href="http://fr.slideshare.net/BNSIT/natural-course-of-refactoring-mixit-lyon">ici</a>.</p>

<p>Ce que je retiendrai, c&#8217;est que le refactoring doit être un travail de tous les jours. Qu&#8217;avec un certain nombre de bonnes
habitudes (voir dans les slides) on peut maintenir du code dans des conditions opérationnelles. Enfin, il ne faut pas se lancer
dans un refactoring complet de tout (trop risqué) mais avoir une approche accès sur l&#8217;efficacité et les &ldquo;quick wins&rdquo;.</p>

<h2>Jeu vidéo: le cousin un peu étrange de l&#8217;IT.</h2>

<p>C&#8217;était une bonne surprise. J&#8217;avais prévu à l&#8217;origine d&#8217;aller à l&#8217;atelier <a href="http://www.mix-it.fr/session/388/application-web-moderne-en-java-the-codestory-way">Application Web Moderne en Java. The CodeStory Way</a> mais faute de place, j&#8217;ai dû me rabattre sur autre chose. Je suis bien tombé.
<a href="https://twitter.com/on_code/">Laurent Victorino</a> est donc un développeur de jeu vidéo qui montrait dans sa <a href="https://speakerdeck.com/lvictorino/mix-it14-jeu-video-le-cousin-un-peu-etrange-de-lit">présentation</a> les préjugès que peuvent avoir les développeurs de jeux vidéo par rapport aux développeurs classiques et inversement. C&#8217;est d&#8217;autant plus intéressant que le speaker a eu une courte exprience en SSII et peu donc comparer les 2 mondes.</p>

<p>Cette présentation m&#8217;a beaucoup plue car comme la plupart des développeurs (enfin je pense), je me suis posé la question de devenir développeur de jeux vidéos ou non. Et finalement j&#8217;ai choisi le développement d&#8217;applications plutot que le développement de jeux. Le speaker a insisté sur le fait que le développement d&#8217;un jeu n&#8217;était pas si compliqué et qu&#8217;il suffisait d&#8217;y consacrer un peu de temps. Un atelier <a href="http://www.mix-it.fr/session/542/unity3d-from-zero-to-hero-basic-session-">Unity3D from zero to hero (Basic session)</a> était d&#8217;ailleurs proposé&hellip; mais j&#8217;ai loupé le début de 20 minutes.</p>

<h2>Machine learning et régulation numérique</h2>

<p>Bonne conférence de <a href="https://twitter.com/glaforge">Guillaume Laforge</a> et <a href="http://www.mix-it.fr/profile/didier.girard">Didier Girard</a> sur le machine Learning. Le plus de leur présentation était de ne pas parler framework mais plutôt d&#8217;algorithmes et de possiblités. Ce que je retiens de leur <a href="http://glaforge.appspot.com/article/machine-learning-a-mix-it-2014">présentation</a> c&#8217;est qu&#8217;il faut stocker le maximum de données possibles, avoir du flair et travailler sur de vraies données.</p>

<p>Ils ont alerté également l&#8217;assemblée d&#8217;être vigilant. Pour eux les développeurs qui font du Big Data ont un peu la même responsabilité que les physiciens qui ont conçu la bombe atomique, c&#8217;est à dire un grand pouvoir. Pour eux il faut avancer sur le sujet de manière éthique et ne pas hésiter à refuser de développer un système qui pourrait être illégal ou non-éthique.</p>

<h2>AngularJS from scratch</h2>

<p>C&#8217;était un très bon atelier et très bien préparé. La pari était de redévelopper un morceau d&#8217;Angular JS en 2 heures. Le challenge semble grand et pourtant on y est arrivé dans le temps imparti. Le gros point fort de cet atelier est qu&#8217;il est accessible et qu&#8217;il permet de démystifier Angular.js en montrant quels sont en fait les simples trucs derrière la magie d&#8217;Angular.</p>

<p>Très très très instructif.</p>

<h2>Open-Sourcing <a href="http://spring.io">http://spring.io</a></h2>

<p>Une très bonne session et une bonne démarche. <a href="https://twitter.com/brianclozel">Brian Clozel</a> nous montrait comment
<a href="http://spring.io/">Spring</a> a développé son site web avec&hellip; Spring. Et le résultat est disponible sur Github sous le nom de
projet <a href="https://github.com/spring-io/sagan">Sagan</a>. Ce qui est intéressant c&#8217;est de voir les technos qui sont poussées par Spring
(gradle, springboot, &hellip;). J&#8217;ai trouvé intéréssant le fait de marquer la différence entre la partie purement HTML avec ses outils
(node, npm, bower, gulp, cram) et la partie traditionnelle java.</p>

<p>Autre point intéressant, c&#8217;est l&#8217;utilisation d&#8217;Elastic Search comme moteur de recherche, ce qui montre à quel point cette solution
s&#8217;est démocratisée.</p>

<h2>Les communautés et le monde IT sous d&#8217;autres cieux</h2>

<p>J&#8217;ai bien aimé cette keynote par <a href="https://twitter.com/horalass">Horacio Lassey-Assiakoley</a> qui nous a un peu expliqué comment sont
organisées les communautés de développement en Afrique Noire. Ce qu&#8217;il faut retenir c&#8217;est qu&#8217;il existe en Afrique Noire des
développeurs aussi motivé que chez nous.</p>

<h2>Programming Diversity</h2>

<p>La dernière keynote, <a href="http://www.mix-it.fr/session/509/programming-diversity-">Programming Diversity</a> par
<a href="https://twitter.com/ashedryden">Ashe Dryden</a> était importante, je pense. Combien de fois, dans notre milieu très masculin,
j&#8217;ai entendu des remarques ouvertement sexistes sur les capacités des développeuses ou ingénieures. Il est donc important de
répéter ce genre de message jusqu&#8217;à ce qu&#8217;il devienne évident à tout notre corporation. Pour le coté &ldquo;racial&rdquo;, j&#8217;ai l&#8217;impression
que nous sommes moins concernés si je considère mes propres experiences professionnelles où la diversité est réelle.</p>

<h2>Mix It Party</h2>

<iframe width="560" height="315" src="http://evidal.github.io//www.youtube.com/embed/R7yfISlGLNU" frameborder="0" allowfullscreen></iframe>


<p>En marge des conférences, la soirée Mix It était une vraie résussite (I&rsquo;m on a boat :&ndash;) ). Je pensais rester une petite heure et
je suis parti après minuit en ayant rencontré plein de monde. A refaire.</p>

<h2>All in all</h2>

<p>Le programme étant riche, il a fallu faire des choix. Cependant, j&#8217;ai eu de très bon échos des conférences suivantes:</p>

<ul>
<li><a href="https://speakerdeck.com/sdeleuze/reactive-applications-with-spring-angulardart-and-websocket">Applications réactives avec Spring4 et AngularDart</a> par <a href="https://twitter.com/sdeleuze">Sébastien Deleuze</a></li>
<li><a href="http://fr.slideshare.net/svenpeters/how-to-do-kickass-software-development">How To Do Kick-Ass Software Development</a> par <a href="https://twitter.com/svenpet">Sven Peters</a></li>
<li><a href="https://speakerdeck.com/garann/how-to-rewrite-your-js-app-at-least-10-times">How to rewrite your JavaScript app ten times</a> par <a href="http://www.mix-it.fr/profile/garann">Garann Means</a></li>
</ul>


<p>Mix It c&#8217;est aussi l&#8217;occasion de croiser d&#8217;anciens collègues ou de faire des rencontres.</p>

<p>Nous avons la chance d&#8217;avoir ce genre de conférence à Lyon, donc merci aux organisateurs.
J&#8217;y retournerai l&#8217;année prochaine.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cordova & Phonegap]]></title>
    <link href="http://evidal.github.io/blog/2014/04/03/cordova-phonegap/"/>
    <updated>2014-04-03T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2014/04/03/cordova-phonegap</id>
    <content type="html"><![CDATA[<p>Dans le cadre d&#8217;un projet, j&#8217;ai développé une petite appli mobile en utilisant <a href="http://cordova.apache.org/">Cordova</a>.
C&#8217;est un outil permettant de créer des applications mobiles multi-support en HTML5 et Javascript.</p>

<p>Le résultat est packagé comme une application mobile standard, par exemple un .apk pour une application Android.
Une fois lancée Cordova fourni un conteneur Web et un &ldquo;bridge&rdquo; qui abstrait les fonctionnalités de l&#8217;OS mobile (Caméra, Contacts, Accéléromètre, etc.)
De nombreux plugins existent et permettent d&#8217;étendre les fonctionnalités de base du framework.</p>

<p>Cordova est issu du Projet <a href="http://phonegap.com/">PhoneGap</a> initié par Adobe. Adobe a ensuite donné la base de code PhoneGap à la fondation Apache qui a créé Cordova. PhoneGap existe encore comme une distribution de Cordova et comme support d&#8217;outils Adobe générant des applications mobiles.</p>

<p>Voilà un petit How-to sur comment mettre en place son environnement de développement Cordova/Android.
Attention, tout environnement pas complétement mal installé sera non fonctionnel et les messages d&#8217;erreurs ne sont pas forcément très explicites.</p>

<h2>Java Development Kit</h2>

<p>Ma configuration utilise le JDK 7, je n&#8217;ai pas testé avec le 8.</p>

<ul>
<li>Téléchargez le pack adapté <a href="le%20http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html">ici</a></li>
<li>Positionnez les variables d&#8217;environement

<ul>
<li>JAVA_HOME

<ul>
<li>sous Linux, <code>export JAVA_HOME="/path/to/jdk"</code></li>
<li>sous Windows, positionnez JAVA_HOME=&ldquo;c:\path\to\jdk&rdquo;

<ul>
<li>dans les variables d&#8217;environnement &ldquo;Start Menu > Computer > Advanced System Settings > Environment Variable&rdquo;</li>
<li>ou dans un cmd.exe, <code>set JAVA_HOME="c:\path\to\jdk"</code></li>
</ul>
</li>
</ul>
</li>
<li>PATH

<ul>
<li>Sous Linux, <code>export PATH=$PATH:$JAVA_HOME/bin</code></li>
<li>sous Windows, ajoutez %JAVA_HOME%\bin au Path

<ul>
<li>dans les variables d&#8217;environnement &ldquo;Start Menu > Computer > Advanced System Settings > Environment Variable&rdquo;</li>
<li>ou dans un cmd.exe, <code>set Path=%Path%;%JAVA_HOME\bin</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Ant</h2>

<p>Ant est une des dépendances</p>

<ul>
<li>Téléchargez la dernière version de ant <a href="https://ant.apache.org/bindownload.cgi">ici</a></li>
<li>Mettez en place la variable d&#8217;environnement ANT_HOME

<ul>
<li>sous Linux, <code>export ANT_HOME="/path/to/ant"</code></li>
<li>sous Windows, positionnez ANT_HOME=&ldquo;c:\path\to\ant&rdquo;

<ul>
<li>dans les variables d&#8217;environnement &ldquo;Start Menu > Computer > Advanced System Settings > Environment Variable&rdquo;</li>
<li>ou dans un cmd.exe, <code>set JAVA_HOME="c:\path\to\ant"</code></li>
</ul>
</li>
</ul>
</li>
<li>PATH

<ul>
<li>Sous Linux, <code>export PATH=$PATH:$ANT_HOME/bin</code></li>
<li>sous Windows, ajoutez %ANT_HOME%\bin au Path

<ul>
<li>dans les variables d&#8217;environnement &ldquo;Start Menu > Computer > Advanced System Settings > Environment Variable&rdquo;</li>
<li>ou dans un cmd.exe, <code>set Path=%Path%;%ANT_HOME\bin</code></li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Android SDK</h2>

<p>Mon but était de faire des applications Android. Si vous avez besoin de générer des applications pour d&#8217;autres plateformes, vous devez installer le SDK pour chaque plateforme visée.</p>

<ul>
<li>Téléchargez la dernière version du SDK <a href="https://developer.android.com/sdk/index.html">ici</a></li>
<li>Mettez en place ANDROID_HOME, attention c&#8217;est bien le SDK qu&#8217;il faut référencer et pas le répertoire contenant Eclipse et le SDK

<ul>
<li>sous Linux, <code>export ANDROID_HOME="/path/to/android/sdk"</code></li>
<li>sous Windows dans les variables d&#8217;environnement &ldquo;Démarrer>Computer>Advanced System Settings>Environment Variable&rdquo; ou <code>set ANDROID_HOME="c:\path\to\android\sdk"</code></li>
</ul>
</li>
<li>PATH

<ul>
<li>Sous Linux,

<ul>
<li><code>
export PATH=$PATH:$ANDROID_HOME/tools
</code>
<code>
export PATH=$PATH:$ANDROID_HOME/platform-tools
</code></li>
</ul>
</li>
<li>sous Windows, ajoutez %ANDROID_HOME%\tools et %ANDROID_HOME%\platform-tools au Path

<ul>
<li>Vous connaissez la manip maintenant :)</li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Node.js</h2>

<p>Il faut la toute dernière version disponible de node.js. Si vous l&#8217;avez déjà, il faut impérativement le mettre à jour.</p>

<ul>
<li>Installation de node JS.

<ul>
<li>sous Windows, il faut télécharger un <em>installer</em> (ici)[<a href="http://nodejs.org/download/">http://nodejs.org/download/</a>]</li>
<li>Sous un Linux, selon votre distrib, faites

<ul>
<li> sous Ubuntu, <code>sudo apt-get install nodejs</code></li>
<li>Sous Fedora/Red Hat/CentOS, <code>sudo yum install nodejs npm</code></li>
</ul>
</li>
</ul>
</li>
</ul>


<h2>Cordova</h2>

<h3>Installation</h3>

<ul>
<li>Installation de Cordova (enlever sudo sous Windows :) )</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo npm install -g cordova</span></code></pre></td></tr></table></div></figure>


<h3>Utilisation</h3>

<p>Créez une application</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cordova create myapp vidal.myapp MyApp
</span><span class='line'>cd myapp</span></code></pre></td></tr></table></div></figure>


<p>Le projet généré est organisé comme ceci:</p>

<ul>
<li><strong>config.xml</strong> contient la configuration,</li>
<li><strong>hooks</strong> est un répertoire pour stocker des commandes customisées Cordova (je ne l&#8217;utilise pas),</li>
<li><strong>merges</strong> est un répertoire que je ne l&#8217;utilise pas,</li>
<li><strong>platforms</strong> est le répertoire qui contient la partie générée spécifique à chaque plateforme. Il faudra aller y faire un tour pour mettre en place les éléments relatifs à un OS (e.g. authorization, rotation lock, &hellip;),

<ul>
<li><em>nom de la plateforme</em>, il y a un sous répertoire par plateforme,</li>
</ul>
</li>
<li><strong>plugins</strong> est le répertoire contenant les plugins installés,

<ul>
<li><em>nom du plugin</em>, il y a un sous répertoire par plugin,</li>
</ul>
</li>
<li><strong>www</strong> est le répertoire qui nous intéresse le plus. C&#8217;est lui qui est considéré comme la racine de votre application. Il contient donc un <em>index.html</em> et toutes les ressources nécessaires à votre application (autres pages html, javascript, images, &hellip;).</li>
</ul>


<p>Comme indiqué plus haut, plusieurs plateformes sont disponibles. Pour avoir la liste, lancez la commande suivante :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cordova platform list</span></code></pre></td></tr></table></div></figure>


<p>Pour faire un projet Android, on va ajouter la plateforme Android au projet.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cordova platform add android</span></code></pre></td></tr></table></div></figure>


<p>Pour accéder aux informations du téléphone comme son identifiant, on peut par exemple utiliser le plugin Device:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cordova plugin add org.apache.cordova.device</span></code></pre></td></tr></table></div></figure>


<p>Un fois ce plugin installé, on aura accès au runtime à un objet javascript <em>device</em> contenant les informations du téléphone.
De nombreux plugins existent au sein du projet Cordova:</p>

<ul>
<li>Accelerometer</li>
<li>Camera</li>
<li>Capture</li>
<li>Compass</li>
<li>Connection</li>
<li>Contacts</li>
<li>Device</li>
<li>Events</li>
<li>File</li>
<li>Geolocation</li>
<li>Globalization</li>
<li>Media</li>
<li>Notification</li>
<li>Splashscreen</li>
<li>Storage</li>
</ul>


<p>Pendant le développement, on peut mocker certains appels à la couche physique comme ceci:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if (navigator.userAgent.match(/(iPhone|iPod|iPad|Android|BlackBerry)/)) {
</span><span class='line'>    document.addEventListener('deviceready', this.splash, false);
</span><span class='line'>} else {
</span><span class='line'>    this.splash();
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Pour faire des tests durant le développement de l&#8217;application j&#8217;ai essayé plusieurs techniques:</p>

<ul>
<li>Utiliser le site local

<ul>
<li>C&#8217;est finalement la manière la plus pratique de fonctionner. Par contre tous les appels à la couche physique ne fonctionnent pas. Il faut donc les mocker.</li>
</ul>
</li>
<li>Utiliser la commande <code>cordova serve</code>

<ul>
<li>ça ne fonctionne pas. Le fichier cordova.js par en boucle infini dans le navigateur.</li>
</ul>
</li>
<li>Utiliser l&#8217;émulateur <a href="http://ripple.incubator.apache.org/">Ripple</a>

<ul>
<li>ça n&#8217;a pas fonctionné mais le projet semble prometteur</li>
</ul>
</li>
<li>Utiliser la commande <code>cordova run android</code> avec l&#8217;émulateur de l&#8217;Android SDK

<ul>
<li>ça marche très mal, pas spécifiquement à cause de Cordova mais plutôt à cause des ressources consommées par l&#8217;émulateur Android</li>
</ul>
</li>
<li>Utiliser la commande <code>cordova run android</code> avec un téléphone branché sur le port USB

<ul>
<li>Finalement c&#8217;est une des solutions les plus rapides à mettre en place.</li>
<li>à noter la commande <code>adb logcat</code> à lancer pour avoir les logs du téléphone et comprendre ce qui se passe.</li>
</ul>
</li>
</ul>


<p>Pour réaliser mon application, j&#8217;étais parti sur l&#8217;utilisation de Boostrap mais le résultat graphique ne faisait pas &ldquo;application mobile&rdquo;. J&#8217;ai donc utilisé <a href="http://jquerymobile.com/">Jquery Mobile</a> qui a un rendu très satisfaisant.</p>

<p>Le résultat final est très bon, rapide et facile à faire par rapport à un développement Android classique.
Avec cette méthode, nous pensons sortir plus facilement des applications au sein de mon entreprise.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Atelier des Objets Connect&eacute;s]]></title>
    <link href="http://evidal.github.io/blog/2013/12/27/atelier-objets-connectes/"/>
    <updated>2013-12-27T00:00:00+01:00</updated>
    <id>http://evidal.github.io/blog/2013/12/27/atelier-objets-connectes</id>
    <content type="html"><![CDATA[<p>Le 12, 19 et 26 novembre j&#8217;ai un suivi une serie d&#8217;<a href="http://www.atelier-objets-connectes.org/">atelier sur les objets connectés</a> proposée par le <a href="http://liris.cnrs.fr/?set_language=fr">LIRIS</a> et le <a href="http://www.fablab-lyon.fr/">Fablab de lyon</a>. Ça fait longtemps que j&#8217;ai envie de manipuler des <a href="http://arduino.cc/">arduino</a>, des <a href="http://www.lego.com/fr-fr/mindstorms/">lego mindstoroms</a> ou de travailler sur un robot. Je m&#8217;étais d&#8217;ailleurs acheté un <a href="http://www.raspberrypi.org/">Raspberry Pi</a> dans ce but, mais faute de temps le Raspberry Pi est resté globalement dans sa boite.
Cet atelier était donc la promesse de manipuler et de pratiquer sur ce genre de materiel.</p>

<p><img src="http://evidal.github.io/images/posts/2013-12-27-atelier-objets-connectes/AtelierObjetsConnectes.jpg" alt="Atelier Objets Connectés" /></p>

<p>Le compte rendu officiel est disponible <a href="http://liris.cnrs.fr/actualites/generales/le-liris-organise-un-atelier-objets-connectes-avec-le-fablab-de-lyon">ici</a>. Un <a href="https://www.facebook.com/groups/368433689954636/?fref=ts">groupe</a> Facebook a également était créé.</p>

<p>Pour un compte-rendu plus détaillé, cliquez sur &ldquo;Lire la suite&rdquo; <!--more--></p>

<h2>Première soirée</h2>

<p>La première soirée a eu lieu à la <a href="http://www.la-cordee.net/la-cordee-liberte-guillotiere/">Cordée Liberté</a>, un espace de coworking qui nous était prété pour l&#8217;occasion. Le but de cette soirée était de faire connaissance avec les différentes personnes, les profils étaient en effet assez différents : des développeurs, des designers, des électroniciens et quelques curieux. Nous avons pu commencer à faire connaissance autour d&#8217;un petit apéro.</p>

<p>Les organisateurs ont ensuite présenté le but de ces ateliers et le materiel à disposition. Il y avait une dizaine de <a href="http://education.lego.com/en-gb/lego-education-product-database/mindstorms-ev3/45544-lego-mindstorms-education-ev3-core-set">kit Lego Mindstorm Eduction</a> :</p>

<p><img src="http://evidal.github.io/images/posts/2013-12-27-atelier-objets-connectes/kit_lego.jpg" alt="Kit Lego" /></p>

<p>et de la même manière une dizaine de kits <a href="http://arduino.cc">Arduino Uno</a> :</p>

<p><img src="http://evidal.github.io/images/posts/2013-12-27-atelier-objets-connectes/ArduinoUno.jpg" alt="Arduino Uno" /></p>

<p>Une imprimante 3D était également disponible durant toutes les sessions. Mais je ne crois pas que quelqu&#8217;un l&#8217;ai utilisée, le problème étant le temps assez limité que nous avions pour réaliser nos idées et le temps que prend l&#8217;impression d&#8217;une pièce 3D.</p>

<p>Les organisateurs ont demandé à l&#8217;assemblée si des personnes avaient des idées, quelques personnes ce sont manifestées et les groupes (une dizaine) ont commencé à se former. De mon coté pas d&#8217;idée précise si ce n&#8217;est que je voulais faire un robot. Au bout du compte en discutant avec d&#8217;autres participant, on a formé une équipe pour faire un robot facteur. L&#8217;idée est de développer un système à la Twitter mais de délivrer les messages de manière réelle. Le nom est trouvé RoboPost.</p>

<p>Au niveau solution technique on est parti sur une solution en Lego. L&#8217;avantage c&#8217;est que tous les catpeurs et actionneurs dont nous avions besoin sont disponibles dans la boite. La seule complexité est de créer une connexion entre une application Web qui va servir pour poster les messages et le robot qui va les distribuer. Pour faciliter la distribution, nous choisissons également de faire simple en décidant que le robot va suivre un itinéraire determiné à l&#8217;avance (un circuit materialisé par une ligne). Les utilisateurs seront identifiés par des stations colorées sur le chemin du robot. Le message sera délivré sur l&#8217;écran de la brique EV3.</p>

<p><img src="http://evidal.github.io/images/posts/2013-12-27-atelier-objets-connectes/CircuitMindstorm.png" alt="Kit Lego" /></p>

<p>Du coup, notre expérimentation fonctionnera avec 4 personnes au plus. L&#8217;idée de départ est de mettre ça en place par exemple autour d&#8217;une table. Et pouruoi pas d&#8217;ajouter également la distribution d&#8217;objets physiques une fois que la premère étape fonctionne.</p>

<h2>Deuxième soirée</h2>

<p>Les équipes étant constituées, notre equipe c&#8217;est retrouvée sur le campus de Lyon 1 dans le batiment Nautibus. Les soirées étant assez courte (2 heures), nous avons du simplifier au maximum tout le fonctionnel qu&#8217;on avait pu imaginer. J&#8217;ai développé le site Web, 2 membres de l&#8217;équipe ont monté le robot et 2 autres se sont occupés de la communication entre le serveur Web et la brique Lego EV3, le cerveau du robot. C&#8217;est d&#8217;ailleurs cette dernière partie qui a le plus posée de problème puisque cela a été le point non-implémenté du projet. Notre équipe c&#8217;est séparée en ayant pas mal de boulot à faire à la maison pour avoir une version démontrable.</p>

<h2>Troisième soirée</h2>

<p>La troisème soirée, toujours sur le campus de Lyon 1, était dédiée à la finalisation des projets et à leur presentation. Notre équipe c&#8217;est concentrée sur la finalisation du robot, les points critiques étant d&#8217;avoir 2 capteurs optiques: l&#8217;un pour suivre le circuit sur et l&#8217;autre pour identifier les stations de couleurs. Au bout du compte nous avons réussi à mettre au point à la dernière minute un robot suiveur de ligne, capable de s&#8217;arréter aux stations colorées, d&#8217;afficher la couleur sur l&#8217;écran et d&#8217;émettre un son (la couleur). Nous n&#8217;étions pas peu fier ;&ndash;) La communication entre le serveur Web et la brique EV3 est elle restée théorique, faute de temps.</p>

<iframe width="560" height="315" src="http://evidal.github.io//www.youtube.com/embed/rthzKnlowL4" frameborder="0" allowfullscreen></iframe>


<p>Les équipes ont ensuite été invitées à présenter à l&#8217;assemblée les différents projets. Voila une petite liste des différents projets:</p>

<ul>
<li><p>Projet Smart Doudou</p>

<ul>
<li>C&#8217;est un doudou connecté ayant la forme d&#8217;un nounours permettant d&#8217;entendre et communiquer avec son enfant et de déclencher différentes actions comme allumer une veilleuse, déclencher des vibrations. Il y avait une application smartphone permettant d&#8217;assurer tout cette communication. Le tout était piloté par un Raspberry Pi car le Mindstorm a une API trop protégée et l&#8217;Arduino ne permettait pas assez de chose. La seule partie manquante était la communication audio avec le doudou via le Smartphone. C&#8217;était une belle réalisation.</li>
</ul>
</li>
<li><p>Projet Robot Musical</p>

<ul>
<li>C&#8217;était un robot Mindstorm piloté avec une tablette pour avancer/reculer. Les notes étaient lues via 2 feuilles de papiers colorées placées sur les cotés du robot. La première donnait le rythme, l&#8217;autre la hauteur des notes.</li>
</ul>
</li>
</ul>


<iframe width="560" height="315" src="http://evidal.github.io//www.youtube.com/embed/UOxhIVVLBQ4" frameborder="0" allowfullscreen></iframe>


<ul>
<li><p>Notre projet RoboPost présenté dans cet article</p></li>
<li><p>Projet de Robot Tourneur de Page</p>

<ul>
<li>Un mécanisme en Lego permettant de tourner les pages</li>
</ul>
</li>
<li><p>Projet de Compteur connecté</p>

<ul>
<li>Un système en Lego Mindstorm permettant de compter des gens entrant dans une boite de nuit (modélisés pour la démo par des bonhommes Lego). Quand la jauge de la boite de nuit est atteinte, la porte se ferme automatiquement. Elle se rouvre quand les gens partent.</li>
</ul>
</li>
</ul>


<iframe width="560" height="315" src="http://evidal.github.io//www.youtube.com/embed/2ZhSBHE3o68" frameborder="0" allowfullscreen></iframe>


<ul>
<li><p>Projet de Prise intelligente</p>

<ul>
<li>Une réalisation à base d&#8217;Arduino et de Raspberry Pi. L&#8217;équipe avait commandé des pièces pour le projet mais n&#8217;avait rien reçu à temps (émeteur/récepteur 433 Mhz). La démo était donc faite avec un câble réseau. Le Raspberry Pi jouait le rôle de la centrale de la maison. Il commandait l&#8217;allumage d&#8217;une LED pilotée par l&#8217;Arduino distant. L&#8217;équipe souhaitait également brancher sur le même système des capteurs de température, de luminiosité, etc&hellip; Leur &ldquo;Reste à faire&rdquo; était assez important (ajouter des relais, émeteurs/récepteurs radio, Interface Web) mais la base était fonctionnelle.</li>
</ul>
</li>
<li><p>Projet ANA</p>

<ul>
<li>Un système permettant de mesurer son exposition aux émissions électromagnétiques et restituer de manière visuelle ce qui est reçu par l&#8217;utilisateur. Le système était basé sur un Arduino.</li>
</ul>
</li>
<li><p>Projet Musicolor</p>

<ul>
<li>Un circuit Arduino déclenchant des notes en fonction des couleurs détectées (rouge, vert, bleu). Comme la plupart des projets (Lego ou Arduino) basés sur la reconnaissance de couleurs, celle-ci est loin d&#8217;être parfaite.</li>
</ul>
</li>
</ul>


<iframe width="560" height="315" src="http://evidal.github.io//www.youtube.com/embed/cMz3axH-ld0" frameborder="0" allowfullscreen></iframe>


<h2>La suite</h2>

<p>C&#8217;était une série d&#8217;ateliers assez intéréssante bien que le temps ait globalement manqué. Nous aurions pu avoirdes projets plus aboutis ou de profiter des imprimantes 3D avec un peu plus de temps.</p>

<p>Le LIRIS prévoie de relancer une série d&#8217;aterlier en 2014 sur un format plus long, j&#8217;espère avoir le temps d&#8217;y participer.</p>

<p>Les sources de notre proto sont disponibles sur ce <a href="https://github.com/titimoby/RoboPoste">repo</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elastic Search en production]]></title>
    <link href="http://evidal.github.io/blog/2013/11/05/elasticsearch-premiere-production/"/>
    <updated>2013-11-05T00:00:00+01:00</updated>
    <id>http://evidal.github.io/blog/2013/11/05/elasticsearch-premiere-production</id>
    <content type="html"><![CDATA[<p>Ça y&#8217;est, j&#8217;ai mis mon premier cluster Elastic Search en production : plus d&#8217;un milliards de documents  et chaque jour environ 500000 nouveaux documents ajoutés. Ça tourne sur 3 nœuds identiques, chacun contient une instance Elastic Search et les applications l&#8217;alimentant et l&#8217;exploitant.</p>

<p>Avoir plusieurs instances d&#8217;un même système facilite la montée en charge car le système supporte les &ldquo;scale out&rdquo; pour absorber plus de données ou plus de charge.</p>

<p>Le paramétrage d&#8217;un Elastic Search en production doit être optimisé sous peine d&#8217;avoir de gros problèmes. Je recommande fortement le visionnage de ce <a href="http://www.elasticsearch.org/webinars/elasticsearch-pre-flight-checklist/">webinar</a> qui permet d&#8217;avoir une idée de tout ce qu&#8217;il faut faire (et de comprendre) pour configurer un Elastic Search en production.</p>

<p>Ce qu&#8217;il faut retenir:</p>

<ul>
<li>Bien dimensionner la mémoire, 1 Go (le réglage par défaut) n&#8217;est pas suffisant</li>
<li>Ne pas allouer plus de 32 Go de Heap Size, le format des pointeurs de la JVM change après cette valeur. Il vaut mieux ajouter un serveur si on est limite au niveau mémoire</li>
<li>Penser à prévoir le double de mémoire physique par rapport au Heap alloué (e.g. si on met 32 Go de Heap, le serveur va en consommer 64 Go physique). Cela est dû à Elastic Search qui utilise massivement le cache du système de fichier.</li>
<li>Prévoir des disques rapides, les &ldquo;disk arrays&rdquo; ne sont pas vraiment utiles.</li>
<li>Préparer le système pour que l&#8217;utilisateur qui lance le process Elastic Search puisse ouvrir le maximum de fichier.

<ul>
<li>Editer <em>/etc/security/limits.conf</em> pour ajouter</li>
</ul>
</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Ensure ElasticSearch can open files and lock memory!
</span><span class='line'>elasticsearch   soft    nofile          65536
</span><span class='line'>elasticsearch   hard    nofile          65536
</span><span class='line'>elasticsearch   -       memlock         unlimited</span></code></pre></td></tr></table></div></figure>


<p></p>

<ul>
<li><ul>
<li>Ensuite dans le .bash_profile de l&#8217;utilisateur ajouter la ligne</li>
</ul>
</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ulimit –n 65536</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Toujours installer la dernière version de Java et d&#8217;Elastic Search, de gros porblèmes sont survenus avec des versions pas à jour de Java.</li>
<li>Attention avec le service Wrapper fourni <a href="https://github.com/elasticsearch/elasticsearch-servicewrapper">ici</a>. Son usage est réservé aux personnes payant la licence pour le composant <a href="http://wrapper.tanukisoftware.com/doc/english/download.jsp">Service Wrapper de Tanuki Software</a>.</li>
<li>Dans conf/elasticsearch.yml

<ul>
<li>Décommentez <em>cluster.name</em> et fixez la même valeur sur l&#8217;ensemble des serveurs,</li>
<li>Décommentez <em>node.name</em> et fixez une valeur différente pour chaque nœud,</li>
<li>Mettre à jour les chemins <em>path.data</em> et <em>path.logs</em> pour les faire pointer en dehors du repertoire d&#8217;installation d&#8217;Elastic Search. Cela permet de bien gérer les montées de versions et de créer des partitions adaptées.</li>
<li>Décommentez <em>discovery.zen.ping.multicast.enabled</em> et mettre à <em>false</em></li>
<li>Décommentez <em>discovery.zen.ping.unicast.hosts</em> et mettre la liste des membres du cluster</li>
<li>Fixez <em>gateway.recover_after_nodes</em> au nombre de noeuds du cluster</li>
<li>Fixez <em>discovery.zen.minimum_master_nodes</em> à (nombre de nodes/2)+1</li>
</ul>
</li>
<li>Mettez en variable d&#8217;environnement de l&#8217;utilisateur la variable <em>ES_HEAP_SIZE</em> et fixez la à la taille coulue (e.g. export ES_HEAP_SIZE=16g)</li>
</ul>


<p>Avec tout ça vous devriez avoir le début d&#8217;un cluster qui fonctionne bien.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Combo Logstash, Elastic Search & Kibana, l'arme absolue des logs]]></title>
    <link href="http://evidal.github.io/blog/2013/09/25/elasticsearch-logstash-Kibana/"/>
    <updated>2013-09-25T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2013/09/25/elasticsearch-logstash-Kibana</id>
    <content type="html"><![CDATA[<p>L&#8217;exploitation des logs sur les applications complexes est assez compliquée. Les applications que mon entreprise développe sont morcelées en plusieurs
couches: Front-End, Back-Enf, Back-Office, Front-Office, Connecteurs, etc&hellip; Chaque application génère ses lots de logs, qu&#8217;ils soient purement techniques
ou bien à but &ldquo;business&rdquo;, dans mon cas des CDR ayant une certaine valeur pour la facturation de nos clients.</p>

<p>Comment avec tous ces logs donner une vision cohérente et syntétique de ce qu&#8217;il se passe sur la plateforme ? Comment archiver ces logs efficacement
pour les 5 prochaines années tout en générant des centaines de milliers de logs ?</p>

<p>La réponse est en utilisant le combo <a href="http://www.elasticsearch.org/">Elastic Search</a>, <a href="http://logstash.net/">Logstash</a> et <a href="http://www.elasticsearch.org/overview/kibana/">kibana 3</a>. <a href="http://logstash.net/">Logstash</a> est une sorte de super ETL permettant de spécifier des entrées, des transformations
et des sorties. La configuration est assez simple et en deux temps 3 mouvements on est capable de configurer un ETL capable de lire tous les fichiers
d&#8217;un repertoire, de les parser intelligemment et de les injecter dans un index <a href="http://www.elasticsearch.org/">Elastic Search</a>. Globalement pour
une ligne de log, on va se retrouver avec un document Elastic Search. La ligne de texte originale est conservée, et plusieurs champs sont créés,
correspondant aux directives que vous configurez dans le fichier de conf Logstash.</p>

<p>Dans mon cas j&#8217;ai utilisé une entrée de type file permettant d&#8217;explorer un repertoire et tout ses sous-repertoires. J&#8217;ai chainé cette entrée avec un
filtre grok qui permet de parser la ligne de log. J&#8217;ai d&#8217;ailleurs utilisé <a href="http://grokdebug.herokuapp.com/">Grok Debugger</a> un outil permettant de tester
des directives sur des logs réels. Si les patterns préprogrammés de GRok sont insuffisant, on peut facielement définir des expressions régulières
permettant d&#8217;étendre les possibilités de Grok. Enfin les logs sont indéxés par Elastic Search, on peut choisir d&#8217;utiliser l&#8217;Elastic Search embarqué
dans Logstash ou de pointer vers un Elastic Search distant (la solution que j&#8217;ai choisi).</p>

<p>On va configurer Elastic Search pour créer un index par mois (ou par jour pour les très gros producteurs de logs). Cela permet de supprimer les documents par lot le moment venu sans &ldquo;casser&rdquo; les index Elastic Search existant. <a href="http://www.elasticsearch.org/">Elastic Search</a> de par son design permet un accès ultra-rapide à n&#8217;importe quelle ligne de log avec la puissance de son module de requêtage et de filtrage.</p>

<p>Enfin <a href="http://www.elasticsearch.org/overview/kibana/">kibana 3</a> (récemment intégré à Elastic Search) permet d&#8217;avoir une visualisation des données de log
et de composer des &ldquo;Dashboards&rdquo; super complet. Par exemple, j&#8217;ai réalisé ce dashboard très facilement à partir des logs de nos applications.</p>

<p><img src="http://evidal.github.io/images/posts/2013-09-25-elasticsearch-logstash-Kibana/kibana.png" alt="Dashboard Kibana MMG" /></p>

<p>Et voilà ! On quelque chose de complet et complétement présentable très rapidement. Le temps de découvrir Kibana et de comprendre comment cela
fonctionnait, j&#8217;ai mis 1 heure. Et tout est connecté, c&#8217;est à dire qu&#8217;on peut modifier les dates en temps réel (zoomer, dé-zoomer, passer en mode temps-réel, etc&hellip;) et tous les graphes se mettent à jour instantanément. C&#8217;est très bluffant.</p>

<p>Bref je recommande vivement l&#8217;utilisation de ce combo qu&#8217;on peut considérer comme l&#8217;arme absolue pour la gestion des logs d&#8217;applications.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dossier Cryptographie]]></title>
    <link href="http://evidal.github.io/blog/2013/09/24/cryptographie/"/>
    <updated>2013-09-24T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2013/09/24/cryptographie</id>
    <content type="html"><![CDATA[<p>Cet article a pour but de présenter quelques éléments concernant la cryptographie, et notamment tous les mécanismes qui sont mis en place dans les cartes à puces et les systèmes qui y sont connectés. L&#8217;article est un peu long, la suite en suivant le lien.</p>

<!--more-->


<h2>Livres</h2>

<p>Tout d&#8217;abord quelques bons livres pour s&#8217;initier à la cryptographie. L&#8217;<a href="http://www.amazon.fr/Histoire-codes-secrets-Simon-Singh/dp/2253150975">Histoire des codes secrets</a> de Simon Singh est un super bouquin de vulgarisation. L&#8217;auteur retrace de l&#8217;antiquité à nos jours  l&#8217;histoire des codes secrets.
C&#8217;est passionnant et ça se lit très facilement (comme un roman).</p>

<p>On m&#8217;a fortement recommandé de lire <a href="http://www.amazon.fr/Secrets-Lies-Digital-Security-Networked/dp/0471453803">Secrets and Lies: Digital Security in a Networked World</a> qui est un livre plus sérieux présentant les différentes solutions qu&#8217;on peut mettre en place pour protéger un système.</p>

<h2>Terminologie</h2>

<p>Parlons un peu terminologie. Dans le monde de la cryptographie, il y a un vocabulaire précis à utiliser.
Tout d&#8217;abord on parle d&#8217;opération de <strong>Chiffrement (encryption)</strong> et <strong>Déchiffrement (decryption)</strong>. L&#8217;encodage et le décodage (par exemple passer une information en BASE64) ne sont pas des opérations cryptographiques.</p>

<p>La science associée à la cryptographie est la <strong>cryptanalyse (cryptanalysis)</strong>. On dit du message original (celui à chiffrer) qu&#8217;il est un <strong>texte brut (plain text)</strong>. Le message obtenu suite à une opération de cryptographie est le texte chiffré (cyphertext). Pour réaliser le chiffrement d&#8217;un message en texte brut, on utilise une <strong>clé de chiffrement (key)</strong>. <strong>L&#8217;ensemble des clés (Key Space)</strong> est l&#8217;ensemble de toutes les clés possibles pour un algorithme de chiffrement donné. Par exemple, pour une clé de chiffrage 10 bits, la taille de l&#8217;ensemble des clés est de 2 puissances 10.</p>

<p>Un <strong>vecteur d&#8217;initialisation (initialization vector)</strong> est une valeur aléatoire combinée avec des portions du message original permettant aux algorithmes de chiffrage d&#8217;éviter les répétitions (et donc d&#8217;être plus facile à casser). On peut parler aussi de <strong>Nonce</strong>.</p>

<p>Un <strong>système cryptographique (Crypto System)</strong> est une combinaison d&#8217;algorithmes permettant de chiffrer/déchiffrer un message. Un <strong>processeur cryptographique (Crypto Processor)</strong> est un processeur permettant de supporter matériellement le processus de chiffrage/déchiffrage.</p>

<h2>Buts d&#8217;un système de Cryptage</h2>

<p>On met rarement en place un système de de cryptographie par plaisir. Un système de cryptage est nécessaire quand on veut implémenter un ou plus plusieurs des points suivants:</p>

<ul>
<li>la <strong>Confidentialité</strong>

<ul>
<li>si quelqu&#8217;un intercepte le message il ne peut rien en faire</li>
</ul>
</li>
<li>L&#8217;<strong>Intégrité</strong>

<ul>
<li>On s&#8217;assure que le message reçu est conforme à l&#8217;aide d&#8217;un Hash</li>
<li>Attention, le concept d&#8217;intégrité ne vaut pas une signature électronique</li>
</ul>
</li>
<li>l&#8217;<strong>Authentification (certificate)</strong>

<ul>
<li>Le message est protégé par une mot de passe</li>
<li>Le message est signé (Digital Signature)</li>
</ul>
</li>
<li>La <strong>Non Répudiation (Identity)</strong>

<ul>
<li>On peut certifier la provenance du message et protéger des usurpations d&#8217;identités</li>
<li>L&#8217;identité est garantie.</li>
</ul>
</li>
</ul>


<h2>Vulnérabilités</h2>

<p>Un système de cryptographie doit être bâti d&#8217;après le <strong><a href="http://fr.wikipedia.org/wiki/Principe_de_Kerckhoffs">principe de Kerckhoffs</a></strong>,
c&#8217;est à dire que la protection ne doit pas résider dans le secret de l&#8217;algorithme, mais plutôt dans la clé. Pour être réellement garanti,
l&#8217;algorithme d&#8217;un système de cryptographie doit être public. La sécurité doit résider dans la clé plutôt que dans le secret de l&#8217;algorithme.</p>

<p>De manière générale, développer son propre algorithme est une très mauvaise idée, et cela pour plusieurs raison. D&#8217;une part, on ne peut
garantir à un tiers l’invulnérabilité  de l&#8217;algorithme. D&#8217;autre part si cela n&#8217;est pas son métier, il y a un risque réel pour créer un système
inefficace.</p>

<p>Il faut également faire attention à l&#8217;ensemble du système, pas seulement la clé et le choix d&#8217;un algorithme. C&#8217;est en effet le maillon le plus faible
de la chaine qui fixe la sécurité globale du système. Si la carte qui implémente le décodage est sensible (par exemple aux surcharges électriques), on
peut arriver a induire des comportements inattendus permettant de déchiffrer le message. Pour pallier à ces faiblesses techniques (qui sont découvertes
au fil de l&#8217;eau), la meilleure solution est de changer régulièrement le système de cryptage. C&#8217;est pour cela par exemple qu&#8217;on change régulièrement de
carte bleue.</p>

<p>Actuellement on considère qu&#8217;une clé de 256 bits est suffisamment complexe pour être protégé pour la durée de vie de m&#8217;univers. En revanche des
failles sont régulièrement découvertes sur les systèmes utilisant ces clés. Donc les &ldquo;pirates&rdquo; ont plus tendances à s&#8217;introduire sur le système recevant
ou émettant le message plutôt que de l&#8217;intercepter.</p>

<p>En France on peut utiliser les algorithmes symétriques DES, 3DES, AES. On est en revanche tenu de déclarer tout importation ou exportation de système cryptographique.</p>

<h2>Les algorithmes symétriques</h2>

<p>Ces algorithmes sont utilisés pour assurer la confidentialité d&#8217;un message et la vérification de l&#8217;intégrité des données. Le principe de ce genre
d&#8217;algorithme est que la même clé est utilisé pour chiffrer et déchiffrer.</p>

<p>Les 3 principaux algorithmes symétriques sont les suivants:</p>

<ul>
<li><a href="http://fr.wikipedia.org/wiki/Data_Encryption_Standard">DES</a> : Il a été créé dans les années 70 par IBM, il était prévu pour tenir 10 ans face aux Hackers. C&#8217;est un système de chiffrage 56 bits. Actuellement ce système de chiffrage est complétement dépassé et ce casse facilement avec des attaques de force brute (Brute Force, on essaye toutes les combinaisons)</li>
<li><a href="http://fr.wikipedia.org/wiki/3DES">3DES</a> : C&#8217;est une variante de DES ou on applique 3 fois le chiffrage DES de différentes façon. Pourquoi 3 fois ? parce qu’apparemment  2 fois ne sert à rien. Ce type de chiffrage est très utilisé dans le monde bancaire. Ce système est actuellement cassé, mais l&#8217;opération reste compliquée à effectuer.</li>
<li><a href="http://fr.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a> : il a était mis au point en 2000 et se base sur une clé pouvant aller de 128 à 256 bits.</li>
</ul>


<p>D&#8217;autres algorithmes existent mais sont moins utilisés: IDEA (très similaire à DES), Blowfish, RC4, RC5, CAST, SAFER, Twofish.</p>

<p>Ce type d&#8217;algorithmes est utilisé pour chiffrer des messages par bloc. En général on prend un bloc faisant la taille de la clé et on complète
avec un motif final pour compléter la fin du message. Il y a plusieurs façons d&#8217;appliquer le chiffrement:</p>

<ul>
<li>ECB (Electronic Code Book), chaque block est chiffré de manière indépendante, ce type d&#8217;application est de moins en moins utilisé, car on peut retrouver des patterns et donc plus facilement cassé le chiffrage</li>
<li>CBC (Cipher Block Chaining) chaque block dépend du bloc précédent, un ou exclusif est appliqué entre le bloc courant et le bloc précédent. C&#8217;est plus sûr mais cela comporte pose problème en streaming. Si on perd un bloc, on ne peut plus déchiffrer le message, il faut donc mettre en place des trames de resynchronisation.

<ul>
<li>L&#8217;avantage de ce mode d&#8217;application, c&#8217;est qu&#8217;il est simple. Cela peut donc fonctionner sur des processeurs très faibles.</li>
</ul>
</li>
<li>OFB (Output Feedback), c&#8217;est sur la clé qu&#8217;on fait un ou exclusif pour ajouter de la &ldquo;variabilité&rdquo;.</li>
<li>CTR (Counter), on prend un nombre aléatoire qui permet de faire varier la clé à chaque chiffrement de bloc.</li>
</ul>


<p>Les algorithmes sont simples et facile à mettre en place mais ils comportent des problèmes quand on veut les utiliser à grand échelle.
En effet pour 5 utilisateurs, on va avoir besoin de 10 clés pour assurer la confidentialité entre chaque personne. Mais si on passe à 10 utilisateurs,
on va avoir besoin de 45 clés et ainsi de suite ( N * (N-1) / 2).</p>

<p>Si on veut garantir un niveau de sécurité élevé tout évitant la génération d&#8217;un grand nombre de clé, il est nécessaire d&#8217;utiliser des algorithmes de
chiffrement asymétrique.</p>

<h2>Les algorithmes asymétriques</h2>

<p>Ce type d&#8217;algorithme a donc été créé au départ pour limiter le nombre de clé à s&#8217;échanger entre utilisateurs. Il est basé sur une clé privée permettant
de chiffrer un message et une clé publique (différente de la clé privée) que l&#8217;on donne aux autres utilisateurs. Cette clé publique permet uniquement de
déchiffrer un message chiffré avec la clé privée de l&#8217;émetteur du message. La clé privée n&#8217;est jamais communiqué aux autres utilisateurs, elle reste secrète.</p>

<p>Ce genre d&#8217;algorithmes est très compliqué et donc très lent. Par exemple un chiffrage RSA est 100 fois plus lents qu&#8217;un DES.
De plus la sécurité de ce genre de chiffrage est basée sur la longueur de la clé. Actuellement RSA 128 bits est cassé et RSA 1024 est sur le point de
l&#8217;être. Il faut donc viser au moins une clé 2048 bits pour être certain d&#8217;assures la confidentialité d&#8217;un message.</p>

<p>L&#8217;avenir de RSA, le principal algorithme de chiffrage asymétrique est difficile à prédire même si pour l&#8217;instant il reste sûr. Un nouveau système est en train d&#8217;apparaitre. Il est basé sur des <a href="http://fr.wikipedia.org/wiki/Cryptographie_sur_les_courbes_elliptiques">courbes elliptiques</a> et il permet de réduire la taille des clés (courbes elliptiques 256 serait équivalent à RSA 4096).</p>

<h2>PKI (Public Key Infrastructure)</h2>

<p>Les PKI sont des systèmes permettant de s&#8217;assurer qu&#8217;une clé est bien distribué à la bonne personne, permettant d&#8217;éviter ainsi une
attaque de type &ldquo;Man in the Middle&rdquo; Pour garantir la distribution des clés, on passe par des autorités de certification. Quand on
reçoit une clé en provenance d&#8217;une autorité, on a la garantie que le message et la clé sont sûrs. La plus connue de ces autorités de
certification est Verisign. De manière générale les autorités de certification sont basées sur un système de certification arborescent,
et dans la plupart des cas, la NSA est haut.</p>

<h2>Echanges de clés</h2>

<p>Pour échanger de manière sûre des clés, des méthodes ont été définie, comme celle de <a href="http://fr.wikipedia.org/wiki/Diffie-Hellman">Diffie-Hellman</a>.
Comment faire quand personne ne connait rien l&#8217;un de l&#8217;autre pour partager une clé. On va par exemple utiliser le RSA pour envoyer une clé symétrique
le temps d&#8217;une transaction.</p>

<h2>Intégrité (hash algorithms)</h2>

<p>Pour vérifier l&#8217;intégrité des données, on utilise des fonctions de hachage. Ces fonctions sont appliquées sur le message en clair, cela permet
de vérifier que pendant la transmission du message, le contenu n&#8217;a pas été altéré. On peut utiliser des algorithmes comme <a href="http://fr.wikipedia.org/wiki/SHA-1">SHA1</a> pour faire ce hachage. On peut aussi utiliser un algorithme de chiffrement pour calculer un HASH et chiffrer le message.</p>

<p>Attention la fonction de HASH ne doit pas être bijective, sinon on peut retrouver le message originel. Il existe plusieurs méthodes, utilisable selon
les cas :</p>

<ul>
<li>Message Digest avec SHA1 dans le mode asymétrique</li>
<li>Message Authentication Code (MAC) dans le mode symétrique</li>
</ul>


<p>Les fonctions de hachage les plus connus sont</p>

<ul>
<li><a href="http://fr.wikipedia.org/wiki/SHA-1">SHA1</a></li>
<li><a href="http://fr.wikipedia.org/wiki/MD5">MD5</a>, des dictionnaires sont disponibles depuis longtemps pour celle-ci</li>
<li><a href="http://fr.wikipedia.org/wiki/HAVAL">HAVAL</a></li>
<li><a href="http://fr.wikipedia.org/wiki/RIPEMD-160">RIPEMD-160</a></li>
</ul>


<h2>Méthodes d&#8217;autentification (Signature Digitale)</h2>

<p>Les fonctions de chiffrement asymétrique sont utilisées également pour signer des documents. La clé privé étant unique, on peut la
considérer comme un signature. Une personne ayant signé un document de sa clé, ne peut pas répudier sa décision.
La signature électronique étant lié à ce qu&#8217;on signe, elle varie en fonction de ce qu&#8217;on signe.
De manière pratique on va signer un document, ou simplement son HASH.</p>

<p>Pour qu&#8217;une signature ait une valeur et qu&#8217;elle ne puisse pas être imitée, on va passer par un organisme de séquestre pour stocker
les documents signés ainsi que les clés publiques. Les signatures électroniques sont basé sur l&#8217;algorithmes <a href="http://fr.wikipedia.org/wiki/Digital_Signature_Algorithm">DSA</a> qui a été introduit quand RSA était encore breveté.</p>

<h2>Infrastructure des PKI (Certificates)</h2>

<p>Les organismes de certifications sont décrits par la norme <a href="http://fr.wikipedia.org/wiki/X.509">X509</a>.
Pour résumlé un PKI c&#8217;est:</p>

<ul>
<li>Séquestre (notarization)</li>
<li>Time Stamping</li>
<li>Non répudiation</li>
<li>Privilege management</li>
</ul>


<p>Un certificat est un moyen de faire confiance à une clé publique. Le certificat n&#8217;est pas une signature. Le certificat n&#8217;est pas un système d&#8217;authentification. Les certificats sont statiques (ils servent à prouver la provenance d&#8217;une clé publique).</p>

<p>e.g. HTTPS (SSL)
La faiblesse de SSL est dans le fait qu&#8217;on identifie pas le client. Du coup on peut multiplier les attaques coté client pour récupérer les clés.</p>

<h2>Les attaques</h2>

<p>On peut attaquer un système en interne (e.g. une carte bleue, une carte SIM, etc.) en électronique pure. Il suffit de tester un composant en injectant différents signaux et voir comment le système se comporte. C&#8217;est pour cela que sur les puces assurant le chiffrement les pates ou les pistes de test ont disparues.
Cela rend plus difficile l&#8217;envoie de signaux (rien n&#8217;empêche par la suite de &ldquo;strapper&rdquo; des pistes sciées sur une carte).
Ces études sont assez compliquées à faire, seul des gouvernements ou des mafias très riches ont les moyens de se payer ce genre d&#8217;étude. Ces groupes
d&#8217;études sont très ingénieux est ont de gros moyens, ils sont capables par exemple de lire la RAM au microscope électronique. C&#8217;est pour cela que
l&#8217;élctronique d&#8217;un système de chiffrement est rendue compliquée:</p>

<ul>
<li>les éléments à l&#8217;intérieur des puces ne sont pas alignés pour éviter une lecture trop facile.</li>
<li>on met des capteurs (lumière, active grid),</li>
<li>on va cacher les éléments (couches, taille, pistes compliquées, bouclier, le bus de transport lui-même sera chiffré)</li>
<li>on rend les choses compliquées (logique redondante)</li>
</ul>


<p>De manière externe on peut injecter des signaux pour provoquer un état imprévu sur le système. Par exemple, certaines puces sont sensibles à certaines
longueurs d&#8217;onde de lumière. On peut aussi injecter des pics de voltage, sur certains vieux systèmes en envoyant des piques de 50V, on pouvait faire
sauter des instructions aux puces. On peut également étudier la consommation électrique d&#8217;une puce pour savoir quelle opération elle est en train d&#8217;effectuer. Pour se protéger de ce genre d&#8217;attaque il faut:</p>

<ul>
<li>réduire le signal du processeur pour que les signaux soit difficile à prélever,</li>
<li>ajouter du bruit pour rendre encore plus difficile le prélèvement des signaux,</li>
<li>supprimer le timing pour être moins sensible à l&#8217;injection de signaux,</li>
<li>modifier l&#8217;ordre des opérations pour une même action,</li>
<li>mettre des capteurs de lumière, de tension, de température pour détecter les attaques,</li>
<li>répéter les opérations pour éviter de se faire injecter des signaux 2 fois,</li>
<li>détruire la puce si problème.</li>
</ul>


<p>J&#8217;espère que cet article aura été instructif et bon point d&#8217;entrée dans le monde de la cryptographie.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lyon Jug Jee8 Avatar]]></title>
    <link href="http://evidal.github.io/blog/2013/03/19/lyon-jug-jee8-avatar/"/>
    <updated>2013-03-19T00:00:00+01:00</updated>
    <id>http://evidal.github.io/blog/2013/03/19/lyon-jug-jee8-avatar</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Angular.js et Yeoman]]></title>
    <link href="http://evidal.github.io/blog/2013/02/24/angular.js-et-yeoman/"/>
    <updated>2013-02-24T00:00:00+01:00</updated>
    <id>http://evidal.github.io/blog/2013/02/24/angular.js-et-yeoman</id>
    <content type="html"><![CDATA[<p>Je suis allé au <a href="http://lyonjs.org/">LyonJS</a> ce 18 février 2013, c&#8217;était mon premier User Group JS&hellip; et je pense que je reviendrais. Les sujets présentés étaient <a href="http://angularjs.org/">Angular.js</a>, <a href="http://yeoman.io/">Yeoman</a> et un lightning talk sur les Web Workers.</p>

<p>Premier contact donc avec Angular avec la présentation de <a href="https://twitter.com/ThierryChatel">Thierry Chatel</a> qui nous fait un petit historique sur Angular et qui nous expose les bases du framework.</p>

<p>Sa présentation est suivie d&#8217;une super séance de live coding faite par <a href="https://twitter.com/Swiip">Matthieu Lux</a>. Yeoman est un outil permettant de gérer les dépendances de ses projets Javascript. Il intégre 3 outils:</p>

<ul>
<li>Yeoman qui permet d&#8217;initialiser un projet JS en configurant des outils standard JS</li>
<li>Grunt, un outil de build, preview et test JS préconfiguré par yeoman</li>
<li>Bower, l&#8217;outil de gestion de dépendance intégré à Yeoman</li>
</ul>


<p>Matthieu installe donc Yeoman et initie un projet Angular à l&#8217;aide de Yeoman. Ces outils pour cette présentation sont IntelliJ IDEA, une console bash et Google Chrome. Pour la partie service, il utilise une base Mongo DB hébergée chez <a href="https://www.mongohq.com/">Mongo HQ</a> &ldquo;attaquée&rdquo; via des services REST préalablement développés et déployés.</p>

<p>Le projet est initialisé simplement avec la commande yeoman. L&#8217;outil pose un certain nombre de questions (Bootstrap/pas Boostrap, Compass/pas Compass, etc&hellip;). Matthieu ajoute ensuite la dépendance vers Angular (même si un initialiseur Angular existe) pour montrer comment on peut ajouter des éléments à un projet existant.</p>

<p>Une fois le projet initialisé il lance le serveur Web intégré et il peut vérifier le résultat dans Chrome. La nature d&#8217;Angular fait que la page est mise à jour en continu, donc tout changement fait au niveau du HTML est immédiatement pris en compte sur le navigateur. C&#8217;est assez plaisant car avec 2 écrans pour développer, on peut avoir un écran avec le code source et un écran avec le résultat avec un affichage temps réel.</p>

<p>Matthieu a réalisé en 1 heure un projet permettant de gérer une liste avec création/édition/suppression d&#8217;items. Ce qui m&#8217;a plu c&#8217;est la concision et la clarté avec laquelle est structuré ce petit exemple. Le même code écrit uniquement avec JQuery aurait été beaucoup plus volumineux et certainement moins clair.</p>

<p>Bonne cession qui m&#8217;a en tout cas donné envie de me plonger un peu plus sérieusement sur tous ces frameworks Javascript.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mon premier sprite en HTML 5]]></title>
    <link href="http://evidal.github.io/blog/2012/10/24/mon-premier-sprite-en-HTML-5/"/>
    <updated>2012-10-24T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2012/10/24/mon-premier-sprite-en-HTML-5</id>
    <content type="html"><![CDATA[<p>Bon ça traîne depuis un petit moment sur mon disque mais voilà ma première utilisation du composant HTML5 canvas.</p>

<p>C&#8217;est le petit Zangief qui a été mis à contribution.</p>

<p>Le source est disponible sur GitHub sous mon projet <a href="https://github.com/evidal/HTML5tests">HTML5tests</a>.</p>

<p>Le resultat de ce test est <a href="http://htmlpreview.github.com/?https://github.com/evidal/HTML5tests/blob/master/canvas.html">ici</a></p>

<iframe src="http://htmlpreview.github.com/?https://github.com/evidal/HTML5tests/blob/master/canvas.html" width="100%" height="600px"></iframe>


<p>Bizarrement je m&#8217;attendais à ce que ce soit beaucoup plus difficile pour avoir un résultat fluide. N&#8217;étant pas un artiste, ce qui a été le plus long a été de trouver les sprites. Du coup ça m&#8217;a donné plein d&#8217;idées et j&#8217;ai téléchargé tout un tas d&#8217;autres sprites (dispo dans mon projet GitHUB <a href="https://github.com/evidal/HTML5tests">HTML5tests</a>).</p>

<p>Je ferai une mise à jour de l&#8217;article avec les différents liens qui m&#8217;ont permis d&#8217;atteindre ce résultat.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elastic Search]]></title>
    <link href="http://evidal.github.io/blog/2012/10/18/elastic-search/"/>
    <updated>2012-10-18T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2012/10/18/elastic-search</id>
    <content type="html"><![CDATA[<p>Elastic Search est un moteur de recherche basé sur Lucene expérimenté par la société
dans laquelle je travaille depuis un certain temps. Ce moteur était présenté
dans le cadre du Lyon JUG par <a href="http://dev.david.pilato.fr/">David Pilato</a> et <a href="https://twitter.com/tlrx">Tanguy Leroux</a>.</p>

<p>L&#8217;interview pre-JUG par les Duchess est disponible <a href="http://www.duchess-france.org/rencontre-avec-david-pilato-sur-elastic-search/">ici</a>.
La présentation elle même est disponible <a href="http://t.co/piqUOkTE">ici</a>.</p>

<p>Je ne vais pas réexpliquer le fonctionnement d&#8217;Elastic Search car de nombreux articles le font déjà (et notamment la présentation de David Pilato).
De notre coté nous avons sélectionner Elastic Serach pour plusierus fonctionnalités importantes pour nous:</p>

<ul>
<li>Nos logicielles sont déployés sur des clusters pour avoir un fonctionnement Actif-Actif. C&#8217;est une des fonctionnalités de base d&#8217;Elastic Search.</li>
<li>Nous manipulons des données très volumineuses en terme de nombre (plusieurs dizaines, voir centaines de millions). Elastic Serach est &ldquo;taillé&rdquo; pour ce volume.</li>
<li>La navigation par &ldquo;Facet&rdquo; qui nous est nécéssaire</li>
</ul>


<p>Cependant nous en sommes encore au stade de l&#8217;étude et nous n&#8217;avons pas encore de vrai déploiement utilisant cette technologie.</p>

<p>Voilà quelques points importants que j&#8217;ai noté pour mémoire:</p>

<ul>
<li>Sécurisation,

<ul>
<li>pour l’instant Elastic Search n’est pas sécurisé. Il est possible qu’il le devienne mais pas dans les toutes prochaines versions.</li>
<li>1ère stratégie : mettre un apache devant et « jouer » avec les règles d&#8217;un firewall (DMZ)
<strong> ajouter une couche http authent pour l&#8217;accès
</strong> utiliser des filtres pour restreindre l’utilisation de certaines commande (comme DELETE, PUT)
** en séparant les index, on peut spécifier des chemins d’accès à des données et gérer des profils</li>
<li>2ème stratégie, utiliser le plugin suivant <a href="https://github.com/sonian/elasticsearch-jetty">https://github.com/sonian/elasticsearch-jetty</a> (solution recommandé uniquement par 1 des speakers)</li>
</ul>
</li>
<li>Cluster et déploiement

<ul>
<li>Les préconisation de déploiement sont de 1 shard par serveur (1 shard = 1 instance de Lucene) + 1 replica</li>
<li>/!\ on ne peut pas changer le nombre de shards une fois qu’un index est crée</li>
<li>Les intervenants recommandent de bien dimensionner son cluster dès le départ, rajouter un nouveau membre au cluster est assez lourd en terme de consommation sur des indexes volumineux</li>
<li>Il est préférable d’effectuer les montées de version à froid (même si des procédures à chaud existent)</li>
<li>D’après le concepteur d’Elastic Search si une requête met plus de 100ms, c’est que la plate-forme est sous dimmensionné.</li>
</ul>
</li>
<li>Il existe une JDBC River qui permet automatiquement d’indexer une table au fil de l’eau

<ul>
<li><a href="https://github.com/jprante/elasticsearch-river-jdbc">https://github.com/jprante/elasticsearch-river-jdbc</a></li>
</ul>
</li>
<li>Un projet d’indexation de Log existe déjà

<ul>
<li><a href="http://logstash.net/">http://logstash.net/</a></li>
</ul>
</li>
<li>Déploiement de références

<ul>
<li>Des déploiements existent avec 25 noeuds indexant plus d’1 milliard de documents</li>
<li>Le premier intervenant (David Pilato) a travaillé sur un projet indexant 500.000 documents des douanes françaises. Le projet tournait sur 3 serveurs low end (CPU 2 cores, mémoire 4GB)</li>
<li>Le deuxième (Tanguy Leroux) a travaillé pour un assureur pour indexer 20.000.000 documents (chaque document était l’équivalent d’une page word). Le projet tournait sur 4 serveurs low end (CPU 2 cores, mémoire 4GB)</li>
</ul>
</li>
<li>Utiliser Elastic Search comme un entrepot de données

<ul>
<li>le créateur le déconseille pour l&#8217;instant mais ce sera peut-être possible à l&#8217;avenir.</li>
<li>Un des intervenant a indiqué qu&#8217;il connaissait un projet utilisant Elastic Search comme base de données principale. Mais dans ce cas il fallait faire une croix sur les transactions et autres fonctionnalités d&#8217;une base de données.</li>
</ul>
</li>
</ul>


<p>Session très intéréssante et speakers disponibles pour répondre aux questions !</p>

<p>Merci le Lyon JUG.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sophisme et Spring]]></title>
    <link href="http://evidal.github.io/blog/2012/07/24/sophisme-et-spring/"/>
    <updated>2012-07-24T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2012/07/24/sophisme-et-spring</id>
    <content type="html"><![CDATA[<p>Une petite note en passant suite aux commentaires d&#8217;un fournisseur (qui m&#8217;énerve).</p>

<p>Ce fournisseur donc aime bien travailler avec Spring, ils sont à l&#8217;aise avec et travaille plutôt bien dessus.
Ces gens là donc sont en train de récupérer un logiciel pour en assurer sa maintenance et sa roadmap.
Une de leur mission et d&#8217;améliorer les tests unitaires qui sont pour l&#8217;instant faible, et la c&#8217;est le drame (avec le ton d&#8217;Enquêtes exclusives ).</p>

<p>Voila leur argumentaire:</p>

<ul>
<li>Spring c&#8217;est super testable</li>
<li>Votre application utilise des EJB (NB: JEE 1.5, EJB 3.1)</li>
<li>Votre application n&#8217;est pas testable, il faut tout injecter à la main, c&#8217;est trop compliqué.</li>
<li>Vous auriez dû utiliser Spring</li>
</ul>


<p>AAaaaaah mais que ça me fatigue/énerve.</p>

<p>Disclaimer : Je considère que le système d&#8217;injection de Spring ne sert à rien dans un serveur d&#8217;application depuis JEE 1.5.
Après pour les autres éléments &ldquo;Springuiens&rdquo;, c&#8217;est une autre histoire.
D&#8217;autant plus que l&#8217;utilisation de JEE ou Spring n&#8217;est pas exclusive !</p>

<p>Quand j&#8217;entends des arguments du genre Spring c&#8217;est mieux parce que c&#8217;est plus simple à tester, ça me fait juste bondir. C&#8217;est un argument moisi.
Il serait beaucoup plus honnête et acceptable de dire &ldquo;je suis plus à l&#8217;aise avec Spring qu&#8217;avec JEE 1.5, alors s&#8217;il te plait laisse moi utiliser Spring&rdquo;.
Ça je pourrais l&#8217;entendre. Le reste, c&#8217;est juste de l&#8217;incompétence.</p>

<p>Pour mémoire &ndash;> <a href="http://www.adam-bien.com/roller/abien/entry/unit_testing_ejb_3_1">http://www.adam-bien.com/roller/abien/entry/unit_testing_ejb_3_1</a></p>

<p>ou alors</p>

<p><a href="http://www.jboss.org/arquillian.html">http://www.jboss.org/arquillian.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pas de test en JEE]]></title>
    <link href="http://evidal.github.io/blog/2012/07/24/excuse-test/"/>
    <updated>2012-07-24T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2012/07/24/excuse-test</id>
    <content type="html"><![CDATA[<p>Une petite note en passant suite aux commentaires d&#8217;un fournisseur (qui m&#8217;énerve).</p>

<p>Ce fournisseur donc aime bien travailler avec Spring, ils sont à l&#8217;aise avec et travaille plutôt bien dessus.
Ces gens là donc sont en train de récupérer un logiciel pour en assurer sa maintenance et sa roadmap.
Une de leur mission et d&#8217;améliorer les tests unitaires qui sont pour l&#8217;instant faible, et la c&#8217;est le drame (avec le ton d&#8217;Enquêtes exclusives ).</p>

<p>Voila leur argumentaire:</p>

<ul>
<li>Spring c&#8217;est super testable</li>
<li>Votre application utilise des EJB (NB: JEE 1.5, EJB 3.1)</li>
<li>Votre application n&#8217;est pas testable, il faut tout injecter à la main, c&#8217;est trop compliqué.</li>
<li>Vous auriez dû utiliser Spring</li>
</ul>


<p>&ndash;> On testera pas</p>

<p>AAaaaaah mais que ça me fatigue/énerve.</p>

<p>Quand j&#8217;entends des arguments du genre Spring c&#8217;est mieux parce que c&#8217;est plus simple à tester, ça me fait juste bondir. C&#8217;est un argument moisi.
Il serait beaucoup plus honnête et acceptable de dire &ldquo;je suis plus à l&#8217;aise avec Spring qu&#8217;avec JEE 1.5, alors s&#8217;il te plait laisse moi utiliser Spring&rdquo;.
Ça je pourrais l&#8217;entendre. Le reste, c&#8217;est juste de l&#8217;incompétence.</p>

<p>Pour mémoire &ndash;> <a href="http://www.adam-bien.com/roller/abien/entry/unit_testing_ejb_3_1">http://www.adam-bien.com/roller/abien/entry/unit_testing_ejb_3_1</a></p>

<p>ou alors</p>

<p><a href="http://www.jboss.org/arquillian.html">http://www.jboss.org/arquillian.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Groovy 2.0 : Quoi de neuf doc]]></title>
    <link href="http://evidal.github.io/blog/2012/06/07/Groovy-2.0-Quoi-de-neuf-doc/"/>
    <updated>2012-06-07T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2012/06/07/Groovy-2.0-Quoi-de-neuf-doc</id>
    <content type="html"><![CDATA[<p>J&#8217;ai assisté le 16 juin dernier à la présentation Groovy 2.0 par
<a href="http://glaforge.appspot.com/">Guillaume Laforge</a> au
<a href="http://www.lyonjug.org/">Lyon JUG</a>.
J&#8217;ai découvert <a href="http://groovy.codehaus.org/">Groovy</a> il n&#8217;y a pas si longtemps,
c&#8217;était il y a un peu plus de 2 ans. Le but de son utilisation dans notre
application était d&#8217;écrire des règles évaluées à la volée. Finalement une autre
solution a été choisie par l&#8217;équipe mais j&#8217;ai beaucoup aimé la simplicité du
langage.
Depuis ce premier contact, je l&#8217;utilise régulièrement pour la manipulation de
fichier (un peu comme un super script), comme support via grails pour des démos
ou POC et aussi pour ce blog qui est développé avec
<a href="http://gaelyk.appspot.com/">Gaelyk</a>. C&#8217;est donc un langage que j&#8217;apprécie.</p>

<p>La présentation de <a href="http://glaforge.appspot.com/">Guillaume Laforge</a> se déroulait en 2 temps:</p>

<ul>
<li>un rappel des fonctionnalité actuelles de Groovy 1.8</li>
<li>une présentation des nouveautés Groovy 2.0</li>
</ul>


<p>Cette présentation est accessible sur Slideshare
<a href="http://www.slideshare.net/glaforge/groovy-20-devoxx-france-2012">ici</a>.</p>

<p>Honnêtement le rappel des fonctionnalités était salutaire. Comme j&#8217;utilise
Groovy comme un meilleur <a href="http://java.com/fr/">Java</a>, il y a certains aspects
du langage que je n&#8217;utilise pas comme GPars (un équivalent de <a href="http://akka.io/">AKKA</a>)
ou trop partiellement comme le commande chain ou je me limite par reflexe.
La présentation m&#8217;a clairement montré que j&#8217;avais besoin de me plonger
sérieusement dans la doc de Groovy pour en exploiter toutes ces facets
(ou du moins mieux les connaitre).</p>

<p>Concernant la version 2.0 de Groovy, les évolutions concerne moins le langage
que la plate-forme. Cette nouvelle version est modulaire, c&#8217;est à dire qu&#8217;au lieu
d&#8217;avoir un groovy-all.jar (qui existe encore), on peut prendre d&#8217;autres jars qui
sont des sous modules de Groovy. Le but de cette modularité est de faciliter
l&#8217;utilisation de groovy dans des applications mobiles par exemple, car on va
réduire la taille de l&#8217;application.
Le reste des évolutions concerne l&#8217;adaptation de Groovy aux nouvelles
fonctionnalités de Java 7 permettant d&#8217;intégrer les nouveautés du langage Java
(<a href="http://openjdk.java.net/projects/coin/">projet Coin</a>) et d&#8217;améliorer les
performances de Groovy. Les performances sont maintenant très proches de Java.
Enfin le compilateur Groovy a été amélioré pour être plus râleur et signaler
les erreurs de compilations qui n&#8217;apparaissaient avant qu&#8217;à l&#8217;exécution. Il
permet également maintenant de faire de compilation statique du code.</p>

<p>J&#8217;ai beaucoup aimé cette session et je vais essayer d&#8217;appliquer tout ça notamment
en refondant ce site. Sa vitesse ne me satisfait pas pour l&#8217;instant. Quand à Groovy
le langage est clairement facile et puissant. Sa syntaxe proche de Java fait qu&#8217;il
est très simple à apprendre et petit à petit, avec l&#8217;experience, on incorpore
les spécificités du langage : closure, GDK, JSon, parsers&hellip; Je n&#8217;ai jamais fait de
Scala (qui a le même âge que Groovy) ou de Clojure (plus jeune) mais quand je lis
des sources de ces langages, leur lecture ne me semble pas simple. Avec Groovy,
même quand j&#8217;ignorais les rudiments du langage, le lecture des exemples était
facile pour moi.</p>

<p>Bref, vive Groovy !</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mix-IT 2012]]></title>
    <link href="http://evidal.github.io/blog/2012/04/28/Mix-IT-2012/"/>
    <updated>2012-04-28T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2012/04/28/Mix-IT-2012</id>
    <content type="html"><![CDATA[<p>J&#8217;étais avant-hier à Mix-IT 2012 er j&#8217;ai passé un très bon moment. Bravo à l&#8217;organisation pour avoir fait intervenir des speakers de qualité dans un cadre agréable pour seulement 30€. J&#8217;ai participé aux keynotes de bienvenu et à 6 conférences : Social Architecture, Lean Startup, lightning talks, Development Process at Google, Phone Gap et Zero MQ. Je n&#8217;ai malheureusement pas pu assister à la keynote finale de Pamela Fox.</p>

<!--more-->


<h2>Keynotes</h2>

<p>En fait il y avait 2 keynotes d&#8217;accueil, je vais passer rapidement sur la première qui n&#8217;était en fait qu&#8217;une présentation de Chrome Mobile. En revanche, la 2ème était vraiment rafraîchissante. Claire Blondel c&#8217;est présenté à nous comme une Alien : c&#8217;est une fille et elle ne fait pas d&#8217;informatique. Elle est venue nous parler de notre droit à échouer. Ca réflexion a commencé quand elle est parti quelques années à l&#8217;étranger. Ces filles sont allées à l&#8217;école la bas et ont adoré ça. Puis lorsque toute la famille est rentrée en France, ses filles ont commencé à détester l&#8217;école et à y être mauvaises. En creusant elle s’est aperçu que ces filles étaient bloquées car elles avaient peur d&#8217;échouer. Et cette peur les bloquait totalement et les empêchait de faire des progrès. Par la suite tout c&#8217;est arrangé pour ces filles mais elle a tiré de cette expérience que la peur de se tromper est un vrai frein. Après tout que peut-il nous arriver si nous échouons. Cette réflexion  4 principes que nous devrions appliquer pour ne plus avoir peur d&#8217;échouer et donc devenir finalement entreprenant dans notre vie de tous les jours et dans notre travail. J&#8217;ai beaucoup aimé sa présentation.</p>

<h2>Social Architecture 101</h2>

<p>J&#8217;ai enchainé avec la présentation de <a href="http://www.mix-it.fr/profile/hintjens">Pieter Hintjens</a>. Bon j&#8217;avoue, ce n&#8217;était pas tout à fait ce que j&#8217;attendais mais la présentation était intéressante. Pieter était là pour expliquer comment construire un projet et monter une équipe efficace. Je pense que cette présentation a été un peu traumatisante pour certains car Pieter a une approche un peu brutale pour un français : on vire les gens quand ils sont mauvais, on définit des règles et on s&#8217;y tient, sinon on part. De la même façon il considère que tout projet ne s&#8217;appuyant pas sur GitHub et un licence GPL est au pire une hérésie et au mieux une perte de temps et d&#8217;argent. Il nous a également donné sa vision pour construire une équipe: pas les meilleurs développeurs du monde mais des gens engagés et capables de travailler ensemble. De manière générale il voit son rôle de manager comme quelqu&#8217;un qui est là pour résoudre tous les problèmes qui pourrait ralentir l&#8217;avancement du projet. Brutal mais intéressant.</p>

<h2>Lean Startup</h2>

<p>Lean Startup était une session introduisant la méthode Lean, donner ses grands principes.  <a href="http://www.mix-it.fr/profile/PIA_Emmanuel">Emmanuel Levi-Valensi</a> voit la méthode Lean comme une méthode rigoureuse permettant de mêler les méthodes agiles et le Customer Development. La présentation c’est axée sur cette dernière méthode permettant de capter l’avis d’un client. L&#8217;idée du Lean c&#8217;est de fournir au plus vite un Minimal Viable Product aux clients et mesurer de manière effective si le produit rencontre sa clientèle ou non. En fonction de ces retours on peut être amené à faire des &ldquo;Pivots&rdquo; consistant à changer le produit, parfois de manière radicale.</p>

<h2>Lightning Talks</h2>

<p>Petite pause déjeuné (plus de sandwich à la viande!) ou j&#8217;ai pu serrer la main de beaucoup d&#8217;anciens collègues, et Lightning Talks. Honnêtement je ne m&#8217;attendais pas à ce que ce format fonctionne : 5 minutes pour parler d&#8217;un sujet, pas de questions. En fait c&#8217;était très bien, ça oblige les speakers à concentrer leur présentation sur l&#8217;essentiel. J&#8217;ai bien aimé la première intervention sur le fait d&#8217;être fier d&#8217;être développeur et l&#8217;intervention Mongo DB.</p>

<h2>Development Process at Google</h2>

<p>A la présentation Development Process at Google, <a href="http://www.mix-it.fr/profile/GooglePetraCross">Petra Cross</a> nous a expliqué comment les ingénieurs chez Google étaient organisés. Il y a 10000 ingénieurs chez Google. Et tous ces ingénieurs travaillent en mode Agile. Ils ne font pas de Scrum, pas de Kanban ni de Xtreme Programming, mais un peu de tout ça mélangé. Les principes d&#8217;organisation sont les suivants, une hiérarchie la plus faible possible et de l&#8217;auto-organisation. Pour être efficace, les équipes sont composées d&#8217;environ 5 ingénieurs : un Tech Lead et 4 ingénieurs. Les items à développer niveau marketing sont mis dans un tas appellé Icebox. De là, le chef de projet va sortir et prioriser les items. Les ingénieurs vont les découper en tâches et estimer ensemble la complexité (pas le temps) grâce au planning poker (on en a eu un en goodies). Si les tâches so)nt trop complexes, elles sont redécoupées. Une fois que tout est découpé, les ingénieurs prennent les tâchent par ordre d&#8217;importance et les réalisent. Pas de filtrage en fonction du niveau de chaque développeur : tout le monde doit être interchangeable. Les revues de code sont obligatoires et un département Q&amp;A valide ou non les développements. Une équipe fait une release toutes les 1 ou 2 semaines. Je ne comprends définitivement pas les boites utilisant encore le cycle en V, permettant au mieux une release tous les 6 mois.</p>

<h2>PhoneGap</h2>

<p>PhoneGap est un sujet qui m&#8217;intéresse particulièrement. La société dans laquelle je travaille réalise depuis peu quelques applications mobiles. Nos développements doivent être supportés par le plus grand nombre d&#8217;appareil et la fragmentation des systèmes est un vrai problème. <a href="http://www.pamelafox.org/">Pamela Fox</a>, une ancienne employée de Google qui a créé un système nommé &ldquo;<a href="http://www.eatdifferent.com">eat different</a>&rdquo;. Vu que c&#8217;est une application qu&#8217;on utilise pendant les repas, il fallait une application mobile. Pamela a exploré plusieurs solutions. L&#8217;approche native a pour avantage d&#8217;utiliser les performances du téléphone ainsi que tous les appareils qui lui sont liés (caméra, Bluetooth, etc.). Cette approche permet d&#8217;être au plus près des API natives et permet de profiter des qualités de l&#8217;OS. Le gros problème de cette approche c&#8217;est que chaque OS mobile a ça propre plate-forme. iOS utilise de l&#8217;Objective C dans l&#8217;ide X-IDE, disponible uniquement sous MAC. Android utilise du Java (Pamela a un problème avec Java, c&#8217;est le langage que son père utilisait &ndash;> je suis vieux) avec l&#8217;IDE Eclipse. Idem pour tous les autres Bada, RIM, Windows, WebOS.</p>

<p>Une autre approche est d&#8217;utiliser un langage qui va, à partir d&#8217;une même source, générer des applications natives pour tous les systèmes. Cette approche permet de conserver la performance mais empêche une utilisation poussée des API natives.</p>

<p>La dernière approche est de développer son application en utilisant un bridge qui va jouer le rôle d&#8217;interface avec l&#8217;OS hôte. C&#8217;est à cette dernière catégorie que Phone Gap appartient. Avec Phone Gap on développe son application en HTML 5, CSS et Javascript. Cela permet d&#8217;utiliser les librairies Javascript habituelles pour réaliser une application tout en ayant accès via le bridge aux capacités du téléphone. Au moment du packaging, Phone Gap intègre les sources HTML, Javascript et CSS et le bridge au sein d&#8217;une application native (un navigateur sur lequel on ne peut pas naviguer en fait). Pour avoir une interface  graphique adapté au mobiles, de nombreuses librairies CSS et Javascript existes JQuery Mobile, Zepto, Twitter Bootstrap (qu&#8217;elle utilise), etc&hellip;</p>

<p>Bonne présentation, je pense que je vais essayer dans peu de temps Phone Gap.</p>

<h2>ZeroMQ, 0MQ</h2>

<p>Dernière présentation pour moi : ZeroMQ avec le retour de la vengeance de Pieter Hintjens. Là encore, c&#8217;était une présentation un petit peu déroutante. Il a expliqué ce qu&#8217;on pouvait faire avec ZeroMQ mais sans vraiment présenter d&#8217;applications, ce qui a perdu je pense une partie de l&#8217;auditoire. Etant dans le monde Télécom, et donc sensible aux questions de messaging, j&#8217;ai pu y voir un interet. Zero MQ est donc pour Pieter l&#8217;aboutissement de que l&#8217;on peut faire dans le monde du messaging. Un système très light écrit en C permettant de supporter des millions de messages secondes. Il est particulièrement adapté aux applications financières traitant un grand nombre de données en temps réel ou aux applications télécoms donc. J&#8217;ai demandé quel était la différence avec AMQP et Zero MQ et&hellip; il m&#8217;a demandé d&#8217;allé voir sur Internet. Ce que j&#8217;ai fait. Ce que je comprends c&#8217;est que si AMQP a une approche classique centralisée, ZeroMQ permet d&#8217;avoir une approche décentralisée pour la distribution des messages. Bon ça reste un peu obscure, je pense que pour comprendre il va falloir y mettre les mains dedans.</p>

<p>Très bonne journée, ambiance détendue, j&#8217;y retournerai l&#8217;année prochaine.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ma&icirc;triser sa production]]></title>
    <link href="http://evidal.github.io/blog/2012/02/21/Maitriser-sa-production/"/>
    <updated>2012-02-21T00:00:00+01:00</updated>
    <id>http://evidal.github.io/blog/2012/02/21/Maitriser-sa-production</id>
    <content type="html"><![CDATA[<p>Un blog un peu court pour expliquer à quel point il est important que les équipes de production soient formées aux environnements d&#8217;exécution qu’elles utilisent. La plupart des administrateurs avec qui j’ai travaillé sont vraiment très bon dans le domaine système, il est beaucoup plus rare qu’ils connaissent aussi nos environnements d&#8217;exécution comme JBoss par exemple.</p>

<p>Bien sur il arrive que les équipes de développement assurent des formations sur l’application que les administrateurs vont déployer. Mais si tous les aspects purement “administratif” sont au mieux passés rapidement, ils sont souvent ignorés.</p>

<p>Et quand on donne des outils aussi puissant qu’un serveur d’application à des administrateurs mal formés, on peut aboutir à des catastrophes. J’ai un exemple récent dans une société dont je tairai le nom d’un serveur JBoss ayant une adresse IP public. Ce serveur avait été installé pour une démo brut de décoffrage, sans paramétrage. Ce qui fait que la console JMX était accessible sans mot de passe, ainsi que la console d’admin qui avait les mots de passe par défaut. Ce serveur c’est fait attaqué. L’attaque a été construite comme cela:</p>

<ul>
<li>scan des ports de la machine</li>
<li>repérage et identification d’un serveur JBoss</li>
<li>repérage que la faille décrite <a href="http://eromang.zataz.com/2011/10/25/jboss-worm-analysis-in-details/">ici</a> fonctionnait bien</li>
</ul>


<p>Et voila un serveur ultra puissant à la merci de pirates.</p>

<p>Ce qu’il faut retenir de cette histoire, c’est qu’un serveur d&#8217;application n’est pas un simple outil qu’on dé-zippe quelque part et qu’on laisser tel quel. De réels efforts doivent être fait pour former les équipes de productions à l’utilisation et à la configuration de tels outils. Une bonne solution est de les faire participer aux tests de performances de l’application. On complétera cette prise en main par une formation adaptée aux problématiques de production (Déploiement, Monitoring, Sécurité, Backup, Restore, Logs, Tunning, etc&hellip;)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tunning de la JVM]]></title>
    <link href="http://evidal.github.io/blog/2012/02/20/Tunning-de-la-JVM/"/>
    <updated>2012-02-20T00:00:00+01:00</updated>
    <id>http://evidal.github.io/blog/2012/02/20/Tunning-de-la-JVM</id>
    <content type="html"><![CDATA[<p>Le 17 janvier 2012 avait lieu une soirée au Lyon JUG ayant pour thème la performance des serveurs en java. Le speaker Ludovic Poitou est un ancien de chez Sun qui a quitté la société suite au rachat par Oracle.</p>

<p>Sa présentation était originale, car contrairement à beaucoup d’entre nous, son logiciel <a href="http://forgerock.com/opendj.html">Open DJ</a> ne tourne pas sur un serveur d’application mais en standalone.</p>

<p>Après une présentation détaillée de sa société, j’ai beaucoup aimé l’explication de la gestion de la mémoire de la JVM. J’avoue que c’est un sujet sur lequel je me suis peu penché car les applications sur lesquelles je travaille n’ont pas le même niveau d’exigence que c’est fixé l’équipe d’Open DJ. L’application la plus “chargée” sur laquelle j’ai travaillé répondait sans broncher à 400 requêtes/seconde HTTP en pointe sur un seul serveur, ce qui est déjà un score honorable sur un serveur d’application d’il y a 5 ans. Mais je ne joue pas dans la même cour, le serveur Open DJ monte à plus de 80000 requêtes/seconde, 200 fois plus de charge.</p>

<p>Pour arriver à ce niveau de performance, il faut avoir une très bonne connaissance du fonctionnement de la JVM, et notamment de la gestion de sa mémoire. Open DJ utilise également une base donnée simple et embarquée : <a href="http://www.oracle.com/technetwork/database/berkeleydb/overview/index.html">Berkeley DB</a></p>

<p>Je vous invite à relire la présentation disponible via le site du Lyon JUG (<a href="http://www.lyonjug.org/evenements/perf-serveur">ici</a>).</p>

<p>Suite à cette présentation je me suis penché sur les paramètres qu’on utilisait pour faire tourner notre JBoss en production. On avait optimisé les options de la JVM de manière un peu empirique, en s’appuyant sur des morceaux de configuration qu’on avait récupéré à travers différents blogs et aussi suite à de nombreuses campagnes de test.
Voilà ce que nous utilisons en production:</p>

<ul>
<li>-d64 : pour faire fonctionner la JVM en 64 bits, et donc adresser au delà de 4Go</li>
<li>-Xms8192m, pour réserver au minimum 8Go de Mémoire vive. C’est une stratégie défensive pour être sur que notre JVM ne se fera pas “piquer” la mémoire par d’autres applications.</li>
<li>-Xmx8192m, pour ne pas dépasser ces fameux 8Go et donc laisser de l’espace aux autres applications tournant sur le serveur.</li>
<li>-XX:MaxPermSize=512m, l’espace la mémoire de type Permanent Generation contient toute les données statiques de la JVM. Il faut qu’il soit suffisamment grand mais pas démesuré. 512 Go est un bon chiffre pour les applications allouant au delà de 8Go de mémoire, il peut être réduit à moins pour les applications plus petite. Il est extrêmement rare d’allouer au delà de 512Mo (jamais vu de mon coté)</li>
<li>-Djava.awt.headless=true, l’option classique pour les serveurs Unix n’ayant pas de serveur X installé</li>
<li>-Dorg.jboss.resolver.warning=true, c’est une option qui était déjà présente. On l’a laissée.</li>
<li>-Dsun.rmi.dgc.client.gcInterval=3600000, c’est une option qui permet de donner la fréquence de garbage collection. En l&#8217;occurrence ça ne sert à rien car nous lui avons donné la valeur par défaut.</li>
<li>-XX:+UseParNewGC, cette option permet de gérer la copie des objets dans la portion de mémoire à plus long terme de manière “multi-threadée” en profitant de la puissance des machines multi-cpu (ce qui est notre cas)</li>
<li>-XX:+AggressiveOpts, je pense que cette option est aussi inutile dans le sens ou elle est devenue activé par défaut depuis la version du JRE 1.5_06. Elle permet d’activer des flags de compilation plus performant.</li>
<li>-XX:+DoEscapeAnalysis, c’est un flag qui permet à la JVM d’optimiser les locks sur l’application, plus d’explication <a href="http://blog.xebia.com/2007/12/21/did-escape-analysis-escape-from-java-6/">ici</a></li>
<li>-XX:+UseLargePages, option permettant d’allouer de gros espaces mémoire, pour plus de détail aller voir <a href="http://www.oracle.com/technetwork/java/javase/tech/largememory-jsp-137182.html">ici</a></li>
<li>-XX:+UseTLAB, option permettant à chaque thread d’allouer sa propre mémoire. C’est une option à activer sur les systèmes multi-processeurs.</li>
<li>-XX:TLABSize=64k, cette option spécifie la taille de la young generation pour chaque thread.</li>
</ul>


<p>Pour compléter ce petit billet, voilà 2 liens utiles</p>

<ul>
<li>la <a href="http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html">documentation</a> officielle de la commande java</li>
<li>un <a href="http://www.datadisk.co.uk/html_docs/java_app/jboss5/jboss5_tuning.htm">blog</a> qui nous avait bien aidé</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gestion des performances]]></title>
    <link href="http://evidal.github.io/blog/2012/01/12/Gestion-des-performances/"/>
    <updated>2012-01-12T00:00:00+01:00</updated>
    <id>http://evidal.github.io/blog/2012/01/12/Gestion-des-performances</id>
    <content type="html"><![CDATA[<p>Je travaille depuis maintenant 2 ans sur un très gros projet qui gère des dizaines de millions d&#8217;utilisateurs. Notre logiciel est donc très sensible à la charge et à toutes améliorations de performance. Voilà une petite liste d&#8217;actions qui permettent de traquer ou de prévenir les problèmes de performances en général.</p>

<h2>Prévention</h2>

<h3>Simplification</h3>

<p>De manière général plus un traitement est simple, plus il est performant. Il faut donc rechercher dans le design la façon de faire la plus simple.
En bonne pratique il faut:</p>

<ul>
<li>ne pas multiplier les couches d&#8217;abstraction. Plus on multiplie les intermédiaires, moins on est réactif.</li>
<li>ne pas multiplier l&#8217;utilisation de librairies techniques (construire de gros échafaudages de librairie). On prend le risque de rendre une fonctionnalité simple beaucoup plus compliquée.</li>
<li>utiliser des environnements maitrisés. Utiliser les dernières technologies c&#8217;est super, mais si on ne maitrise pas tous les impacts, on peut construire de vraies bombes à retardement.</li>
</ul>


<h3>Faire des tests de performance</h3>

<p>Sur notre projet nous avons utilisé JMeter pour simuler du trafic. Attention on ne doit pas seulement faire un hit sur de 2-3 pages mais réaliser un scénario complet et dynamisé.
Par la suite les tests doivent se dérouler sur plusieurs heures ou jours pour voir si la plateforme est stable dans le temps.
Pendant ces tests il ne faut pas forcément essayer de trouver les limites de l&#8217;application mais la soumettre à un stress nominal.
Les tests aux limites sont intéressants mais uniquement si la plate-forme répond correctement au stress nominal.</p>

<h3>Dimensionner l&#8217;infrastructure, limiter la charge</h3>

<p>A partir des tests établis précédemment on peut en déduire des infrastructures cibles.
On ne va pas mettre la même infrastructure chez un client ayant 2 millions de comptes que chez un client ayant 80 millions de comptes.
Il est important de définir ces infrastructures dans les contrats quand on vend le logiciel.
De plus il est important pour les applications critiques de mettre en place des mécanismes de protection pour éviter la saturation de la plate-forme.
On peut par exemple mettre en place un système de licence qui limite le nombre d&#8217;utilisateurs à 10 millions et/ou à un certain nombre de requêtes HTTP par seconde.
Avec cela on garantit le service pour la charge que l&#8217;on a défini contractuellement. Il faudra bien sur penser à ce système dès la conception du logiciel.</p>

<h2>Corrections</h2>

<p>Au niveau développement voilà un certain nombre d&#8217;éléments permettant de traquer les problèmes.</p>

<h3>Optimisation SQL</h3>

<p>De manière générale le tout premier élément limitant d&#8217;un logiciel sur un serveur est la base de données mal utilisée. Il peut y avoir plusieurs causes:</p>

<ul>
<li>mauvais modèle de données</li>
<li>pas d&#8217;index</li>
<li>trop de requêtes SQL</li>
<li>requêtes SQL non optimisées</li>
<li>non maitrise du Framework technique accédant à la base</li>
</ul>


<p>Dans un premier temps, il va falloir tracer les requêtes SQL générées par l&#8217;application. Si vous utilisez Hibernate, vous pouvez par exemple mettre à true le paramètre hibernate.show_sql.
Par la suite vous allez exécuter un scenario de test unitaire sur votre application. Cela va vous permettre d&#8217;identifier les requêtes SQL exécutées à chaque étape de votre scénario.
Des actions doivent être prises si:</p>

<ul>
<li>une même requête est exécutée plusieurs fois pour une étape donnée</li>
<li>une ou plusieurs requêtes inattendues apparaissent (par exemple un delete et des insert alors qu&#8217;on fait un simple select, si si c&#8217;est possible voir [[www.yonita.com/2011_11_16_PERFORMANCE_ANTIPATTERNS_DEVOXX.pdf|ici]])
Ils faut impérativement rester maitre des requêtes faites vers la base de données.</li>
</ul>


<p>Dans un deuxième temps il fait traquer les requêtes consommatrices de ressources. Sur Oracle, on peut utiliser l&#8217;outil Oracle Enterprise Manager qui est une console d&#8217;administration Web de la base de données.
Cet outil permet de monitorer en temps réel la charge de la base de donnée mais aussi d&#8217;avoir la liste des requêtes les plus consommatrices. Un fois ces requêtes identifiées on pourra les optimiser en:</p>

<ul>
<li>ajoutant des index</li>
<li>ajoutant des hints pour l&#8217;optimiseur SQL (les hints sont tout à fait compatible avec des outils comme Hibernate)</li>
<li>en repensant une partie du modèle de base de données pour l&#8217;optimiser</li>
</ul>


<p>Enfin une des dernières optimisations au niveau base de données est de bien préparer la base.
Si le modèle a un impact très fort sur les performances, il ne faut pas négliger la configuration de la base.
Il faut notamment travailler avec un DBA pour optimiser (pour Oracle) la taille des blocs, des redo-logs, des archives-logs.
Attention toutefois à ne pas faire n&#8217;importe quoi, si vous ne maitrisez  pas ces paramètres, n&#8217;y touchez pas.</p>

<h3>Optimisation des Objets/Mémoire/Threads</h3>

<p>Ce paragraphe s&#8217;intéresse à l&#8217;étude et l&#8217;optimisation du code java.</p>

<p>L&#8217;utilitaire jmap permet d&#8217;avoir plus d&#8217;information sur l&#8217;utilisation de la mémoire et des objets. Cet outil est utile pour monitorer la JVM quand elle est stressée de manière normale.</p>

<ul>
<li>jmap -d64 -heap <pid> > heap.txt

<ul>
<li>cette commande permet d&#8217;avoir un état détaillé de la mémoire. Cela vous permettra d&#8217;ajuster les paramètres mémoires de la JVM.</li>
</ul>
</li>
<li>jmap -d64 -histo:live <pid> > histo.txt

<ul>
<li>cette commande permet d&#8217;avoir la liste de toutes les instances tournant dans la JVM. On pourra détecter un trop grand nombre d&#8217;instance pour un type d&#8217;objet.</li>
</ul>
</li>
</ul>


<p>Les applications JEE sont multi-threadés, les threads sont cachés par les APIs de haut niveau de la norme JEE (Servlet, EJB).
Si c&#8217;est API sont mal utilisées, des problèmes de performance apparaissent (notamment des cas d&#8217;inter-blocage).
Pour s&#8217;assurer que notre application n&#8217;est pas dans ce cas, il faut la soumettre à sa charge nominale grâce à des injecteurs ou des outils comme JMeter.
Une fois que l&#8217;application est en cours de fonctionnement, on va faire des Threads Dump de manière régulière pour vérifier qu&#8217;aucun thread n&#8217;est bloqué.
La résolution des cas d&#8217;inter-blocage en changeant l&#8217;implémentation d&#8217;une méthode a souvent des résultats spectaculaires.
A noter que les threads dump en Java se font en envoyant SIGQUIT au process à l&#8217;aide de la commande kill -3 &lt;process_id>.
Sous JBoss on peut faire ça via la console JMX sur le bean ServerInfo.</p>

<p>Une des dernières techniques pour voir plus claire dans le fonctionnement d&#8217;une application. Personnellement j&#8217;ai rarement progressé en profilant une application.
De nombreux outils existent pour profiler une application, cependant un profiler est livré avec le JDK: HPROF. Il peut fonctionner en mode classique (on enregistre tous les évènements) ou en mode sampling (on prend un photo de la JVM toutes les minutes par exemple).
Si on travaille sur environnement stressé, il est préférable d&#8217;utiliser le mode Sampling.</p>

<p>Voilà, c&#8217;était un petit aperçu des différentes techniques que j&#8217;utilise pour améliorer les performances de mes applications. Il en existe certainement bien d&#8217;autres mais celles-ci nous ont bien aidé pour avoir une application performante en production.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cloud Synth&egrave;se]]></title>
    <link href="http://evidal.github.io/blog/2011/07/07/Cloud-Synthese/"/>
    <updated>2011-07-07T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2011/07/07/Cloud-Synthese</id>
    <content type="html"><![CDATA[<p>Le 9 et 10 juin j&#8217;ai eu la chance de participer à synthèse sur les technologies du Cloud.</p>

<p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Cirrocumulus_to_Altocumulus.JPG/800px-Cirrocumulus_to_Altocumulus.JPG" alt="source http://commons.wikimedia.org/" /></p>

<p>Voilà mes notes.</p>

<!--more-->


<h2>Concepts</h2>

<p>Le Cloud est un terme à la mode. Il faut se méfier des imitations. Le Cloud ne veut pas dire
Hosting ou logiciel en ligne. L&#8217;hébergement ou les logiciels accessiblesne sont pas nouveau et
existe depuis longtemps. Le Coud est plus l&#8217;arrivé à maturité de certaines technologies et d&#8217;acteurs IT:</p>

<ul>
<li>La virtualisation est massivement utilisée dans le Cloud</li>
<li>Les applications sont dévenues des application WEB</li>
<li>Les Architecures SOA sont utilisées</li>
<li>Des sociétés IT suffisemment grosse pour inspirer la confiance existe</li>
<li>Les start-up des années 2000 ont eu besoin des technologies Cloud pour exister et grossir</li>
</ul>


<p>Pour résumer les points clés d&#8217;un/e déploiement/applciation Cloud sont:</p>

<ul>
<li>controlable par une API pour couplage au SI</li>
<li>Multi-Tenancy, ou capacité à cohabiter utilisateur du Cloud sans interférence.</li>
<li>Reliability, c&#8217;est à dire pour un coup identique ou moindre, augmenter sa résistence aux aléas d&#8217;un système (composants qui crashent, datacenter qui brulent, etc&hellip;).</li>
<li>Scalability (in and out), être capable de muscler sa solution si besoin ou au contraire diminiuer sa puissance si trop grosse (et payer ce qu&#8217;on utilise).</li>
<li>Performance, la puissance est potentiellement infinie du point de vue de notre utlisation.</li>
</ul>


<p>3 types d&#8217;usages existent:</p>

<ul>
<li>IaaS – Infrastructure as a Service, pour disposer d&#8217;une machine virtuelle dans le Cloud</li>
<li>PaaS – Platform as a Service, Middleware utilisant une infrastructure de type Cloud pour fonctionner et utilisable via une API</li>
<li>SaaS – Software as a Service, un logiciel utilisant une infrastructure de type Cloud pour fonctionner (et intégrable dans son SI via des APIs)</li>
</ul>


<h3>IaaS</h3>

<p>Les offres IaaS (Infrastructure as a Service) proposent de se construire infrastructure dans le Cloud (serveur, réseau). On peut utiliser cette infrastructure comme une extension de son propre système ou comme une infrastructure prête à l&#8217;emploi: on utilise exactement ce dont on a besoin, avec l&#8217;OS qu&#8217;on veut. Si plus (ou moins) de puissance est nécéssaire, on définit des règles pour adapter la puissance dont on a besoin, et donc son coût.</p>

<h3>PaaS</h3>

<p>Le PaaS (Platfom as a Service) vous proposent toute une gamme de middleware prêts à être utilisé. Toutes la partie matériel, système d&#8217;exploitation est complètement masqué, n&#8217;est visible que le middleware. On trouvera dans cette gamme de service des solutions très variées: Base de données (SQL ou non), Serveur d&#8217;Application (Java ou non), des Messages Broker, des solutions de paiements, etc. Comme dans le cas de l&#8217;IaaS ces plateformes sont virtuellement illimitées en terme de puissance et on paye uniquement ce que l&#8217;on consomme.</p>

<h3>SaaS</h3>

<p>Le Software as a Service existe depuis longtemps mais ne doit pas confondu avec des solutions &ldquo;hostées&rdquo;. Les  principales différences avec un service hosté sont les suivantes :</p>

<ul>
<li>le logiciel disponible en mode SaaS est virtuellement illimité en terme de nombre d&#8217;utilisateurs.</li>
<li>des APIs doivent permettre une interconnexion avec d&#8217;autres systèmes (comme le SI)</li>
<li>l&#8217;utilisateur paye pour ce qu&#8217;il utilise
Dans cette gamme de service, la variété de solutions est pléthorique : Suites Bureautiques, Messageries, Wiki d&#8217;entreprise, logiciel de gestion ultra scpécialisé (gestion commerciale), etc.</li>
</ul>


<h3>Sécurité et Cloud</h3>

<p>On voit donc que migrer tout ou partie de ces applications vers le Cloud est très attractif, mais comme pour toute décision, on doit soigneusement réfléchir aux conséquences, notamment en terme de sécurité. Car migrer vers le Cloud ça veut dire donner l&#8217;accès à un tiers à des données qui nous appartiennent, ce qui peut dans certains cas présenter des problèmes légaux ou de confidentialités.</p>

<p>Du coté des points positifs, on retiendra les éléments suivants:</p>

<ul>
<li>Les Administrateurs de ce genre de solutions sont très bons, souvent meilleurs que les personnes dont nous disposons en interne.</li>
<li>Les plateformes (et leurs administrateurs) sont disponibles en 365/7/24 : 365 jours par an, 7 jours sur 7, 24 heures sur 24. Peu d&#8217;entreprises peuvent se permettre une telle disponibilités.</li>
<li>Les infrastructures des ces solutions sont bien mieux protégées des attaques car tous les patchs de sécurité sont appliqués très rapidement et de manière transparente pour les utilisateurs.</li>
<li>Toute l&#8217;infrastructure est redondante donc les pannes matériels sont correctement gérées.</li>
<li>PaaS, IaaS ou SaaS tournent dans des VM, ce qui isole des autres clients et de leur défaillance potentielles (ex. mémoire saturée).</li>
<li>Les données sont distribuées ce qui assure plus de sécurité quand à leur conservation.</li>
</ul>


<p>Mais tous n&#8217;est pas rose, et pour tempérer tous ces points positifs, voila une liste d&#8217;éléments auxquels ont doit réfléchi avant de basculer:</p>

<ul>
<li>Toutes ces solution sont opaques: on ne sait pas comment ça fonctionne, on ne sait pas qui gère notre plateforme, on ne sait pas où se trouve le datacenter, etc.</li>
<li>On doit avoir complètement confiance dans notre fournisseur.</li>
<li>Les possesseurs de la plateforme peuvent accéder à mes données, comment s&#8217;assurer de la confidentialités des données sensibles</li>
<li>Une fois qu&#8217;on utilise plus la plateforme, que deviennent mes données ? Sont-elles détruites ou conservées par mon fournisseur ?</li>
<li>La plupart des administration publique ne peuvent pas utiliser de tels services pour des raisons légales (localisation géographique des serveurs, agrément pour la gestion des données médicales, etc.)</li>
<li>Rien n’empêche le fournisseur de faire de faire du Datamining sur mes données (ex. Google Mail et les publicités)</li>
</ul>


<h3>Cas d&#8217;utilisation</h3>

<p>Venons-en au cas d&#8217;utilisation, c&#8217;est à dire comment utiliser cette technologie dans mon entreprise.</p>

<ul>
<li>Externaliser son IT. Dans ce cas la, je confie à un tiers la gestion des comptes emails, des calendriers partagés, de l&#8217;Intranet, etc&hellip; (Google Apps)</li>
<li>Externaliser sa solution de CRM (Sales Force)</li>
<li>Optimiser ses ressources IT : migrer tous les serveurs dans le Cloud et utiliser la puissance machine uniquement quand c&#8217;est nécessaire.</li>
<li>Application WEB a très forte audience pour être capable de gérer les très grosses montées en charge et être capable de relacher cette puissance par la suite</li>
<li>&ldquo;Business Continuity&rdquo; conserver une partie de ses machines en interne et prévoir un système complet de Fail-Over dans le Cloud.</li>
</ul>


<p>Un des points fort des applications Cloud sont les SLA (Service Level Agreement ou Qualité de Service), mais tout n&#8217;est pas parfait. En effet les plateforme Cloud ont des  SLA très importante (99.999999999 pour Amazon S3) mais il arrive qu&#8217;il y ait des pannes. Tout le monde ce souvient de la grosse panne Amazon en avril 2011 qui a paralysé certains gros site pendant quelques jours. Il faut donc se tenir prêt à ce que le Cloud soit défaillant, voilà quelques idées pour réduire ce risque. Ces idées ne sont pas nouvelles et doivent déjà être mise en oeuvre sur les très gros projets à hébergement classique:</p>

<ul>
<li>Varier les solutions d&#8217;hébergement

<ul>
<li>serveurs internes/externes, 2 fournisseurs Cloud différents,</li>
<li>différents fournisseurs Cloud (Amazon, Google Microsoft, &hellip;)</li>
<li>différentes localisations de datacenter (Amazon Europe, Amazon US East#</li>
</ul>
</li>
<li>Monitorer les applications pour détecter/prévenir les problèmes et réduire les temps d&#8217;indisponibilités.</li>
<li>Etre capable d&#8217;utiliser les API de son fournisseur Cloud pour réagir rapidement</li>
<li>Avoir une plate-forme suffisamment générique pour changer de fournisseur en cas de besoin.</li>
</ul>


<h2>Les offres Cloud</h2>

<p>Il y a 4 &ldquo;gros&rdquo; fournisseurs (Cloud Service Providers) dans le domaines du Cloud:</p>

<ul>
<li><a href="http://aws.amazon.com">Amazon</a></li>
<li><a href="http://www.google.com/Apps">Google Apps</a> et <a href="https://appengine.google.com/">Google App Engine</a></li>
<li><a href="http://www.force.com/">Force</a> et <a href="www.salesforce.com">Salesforce</a></li>
<li><a href="http://msdn.microsoft.com/fr-fr/windowsazure">Microsoft</a> et <a href="http://www.microsoft.com/fr-fr/office365/online-software.aspx">Office 365</a></li>
</ul>


<h3>Amazon</h3>

<p><a href="http://aws.amazon.com">Amazon</a> est l&#8217;un des tous premiers fournisseurs Cloud. La légende (rumeur) veut qu&#8217;ils aient acheté trop de machine à leur début et qui&#8217;ils aient cherché un moyen de les utiliser grâce à de nouveaux services. Amazon est positionné sur les solutions de type IaaS et PaaS avec notamment</p>

<ul>
<li>EC2, Elastic Compute Cloud

<ul>
<li>Location de serveur (avec choix dymanique de la puissance)</li>
<li>Location de Serveur avec HADOOP (pour faire du <a href="http://fr.wikipedia.org/wiki/MapReduce">map reduce</a>)</li>
</ul>
</li>
<li>S3, Simple Storage Service,

<ul>
<li>On peut considérer S3 comme le disque dur d&#8217;Internet. De nombreux services à très forte volumétrie utilisent S3 (comme dropbox)/</li>
<li>SLA : 99,999999999%</li>
<li>La SLA est tellement énorme, qu&#8217;une nouvelle solution moins chère avec des SLA moins élevés est à l&#8217;étude.</li>
</ul>
</li>
<li>et aussi

<ul>
<li>EBS, Elastic Block Store (Disques pour EC2)</li>
<li>SQS, Simple Queue Service (Système de queue)</li>
<li>SNS, Simple Notification System (Messaging en mode push)</li>
<li>Simple DB (Stockage clé/valeur)</li>
<li>RDS, Relational Database Service (MySQL)</li>
<li>Elastic Load Balancing, Elastic IP, Autoscale</li>
<li>VPC, Virtual Private Cloud</li>
<li>&hellip;</li>
</ul>
</li>
</ul>


<p>Pour les développeurs JAVA, une solution est intéressante : Elastic Beanstalk. C&#8217;est la combinaison de tout un tas de service Amazon pour fournir un serveur d&#8217;application JEE prêt à l&#8217;emploi. Point intéressant, si vous utilisez Beanstalk, la première année est gratuite à condition de ne pas dépasser des quotas.</p>

<h3>Google</h3>

<p>Google est positionné sur les SaaS avec <a href="http://www.google.com/Apps">Google Apps</a> et le PaaS avec <a href="https://appengine.google.com/">Google App Engine</a></p>

<ul>
<li>pour <a href="http://www.google.com/Apps">Google Apps</a> on aura à notre disposition

<ul>
<li>Google Docs (Suite Bureautique)</li>
<li>Google Sites (Pour réaliser des sites WEB)</li>
<li>Gmail &amp; Calendar (Email et Calendrier)</li>
<li>Google Groups (Groupe de discussion)</li>
<li>…</li>
</ul>
</li>
<li>et pour <a href="https://appengine.google.com/">Google App Engine</a> on va trouver les services suivants

<ul>
<li>héberger des applications JEE/Python/Go</li>
<li>A noter pour Java seule une partie de l&#8217;API est implémentée. Il faut utiliser les classes de la Google White List</li>
<li>Les quotas gratuits sont assez élevés (moins de 5 millions de pages vues par mois)</li>
<li>Base de données orientée colonnes et un &ldquo;Blobstore&rdquo; pour les fichiers</li>
<li>Et tout un tas de service Google  (Accounts, URL Fetching, MemCache, XMPP, CRON, TaskQueue, Image Processing, Emails)</li>
</ul>
</li>
</ul>


<p>Petit retour d’expérience personnel avec Google App Engine, le principe est vraiment bien par contre j&#8217;ai 2 remarques importantes:</p>

<ul>
<li>d&#8217;une version à l&#8217;autre du SDK, j&#8217;ai certaine fonctionnalité de ce blog qui change.</li>
<li>le comportement du SDK n&#8217;est pas identique au comportement du vrai Google App Engine.</li>
</ul>


<h3>Force.com</h3>

<p>Force.com était un acteur que je ne connaissais pas (bien que ma boite utilise Salesforce sans que je le sache). Ils ont commencé avec le SaaS <a href="www.salesforce.com">Salesforce</a> puis ils on peu à peu créé une offre Paas avec <a href="http://www.force.com/">Force.com</a>.
Voila un aperçu de leurs solutions:</p>

<ul>
<li>SaaS

<ul>
<li><a href="http://www.salesforce.com">Sales Force</a>, outil CRM</li>
<li>JigSaw, Customer Service</li>
<li><a href="http://www.salesforce.com/remedyforce/">RemedyForce</a>, Gestion de Helpdesk</li>
<li><a href="http://www.salesforce.com/fr/chatter/">Chatter</a>, (Twitter, Facebook et chat pour Entreprise)</li>
<li><a href="http://www.radian6.com/">Radian 6</a>, Social Network Listener</li>
<li>&hellip;</li>
</ul>
</li>
<li>PaaS avec Force.com

<ul>
<li><a href="http://www.heroku.com/">Heroku</a> qui est un hébergeur Node.js et Ruby</li>
<li><a href="http://database.com">Database.com</a> une base de donnée Cloud</li>
<li><a href="http://www.salesforce.com/platform/appforce/">AppForce</a> pour écrire des applications avec un L4G pour Force.com</li>
<li><a href="http://www.force.com/products/index.jsp?a#1&amp;slide#1">SiteForce</a> pour créer des sites WEB</li>
</ul>
</li>
</ul>


<h3>Azure</h3>

<p><a href="http://msdn.microsoft.com/fr-fr/windowsazure">Azure</a> est la solution de Microsoft. D&#8217;après le formateur, c&#8217;est des meilleurs infrastructure technique qu&#8217;il connaisse. La ou le bas blesse pour le formatteur, c&#8217;est au niveau des offres. Pour lui quand on prend un service Cloud chez Microsoft, on s&#8217;attendrait à avoir un Exchange prêt à l&#8217;emploi ce qui n&#8217;est pas directement possible apparemment. L&#8217;offre de Microsoft est en fait beaucoup plus orientée vers les développeurs avec:</p>

<ul>
<li>intégration dans Visual Studio</li>
<li>Instanciation de de Serveur Windows</li>
<li>Service Bus</li>
<li>SQL Server dans le Cloud</li>
<li>Blob Storage (stockage binaire)</li>
<li>Workers (genre de traitement batch)</li>
<li>Web</li>
</ul>


<p>L&#8217;autre offre de Microsoft est <a href="http://www.microsoft.com/fr-fr/office365/online-software.aspx">Office 365</a>. C&#8217;est une offre qui permet d&#8217;utiliser les outiles bureautique de la suite Office en mode Web.</p>

<h3>Autres Offres</h3>

<p>Il existe tout un tas d&#8217;autres offres</p>

<ul>
<li>IaaS

<ul>
<li><a href="http://www.gogrid.com/">GoGrid</a></li>
<li><a href="http://www.rackspace.com/">Rackspace</a></li>
<li><a href="http://www.joyent.com/">Joyent</a></li>
<li><a href="http://www.orange-business.com/fr/entreprise/portfolio/catalogue/toutes-solutions/flexible-computing.html">Orange Flexible Computing</a></li>
<li><a href="http://www.ovh.com">OVH</a></li>
</ul>
</li>
<li>PaaS

<ul>
<li><a href="http://www.gridgain.com/">GridGrain</a></li>
<li><a href="http://www.gigaspaces.com/">GigaSpaces</a></li>
<li><a href="http://www.cloudbees.com/">Cloud Bees</a></li>
<li><a href="http://www.cloudfoundry.com/">Cloud Foundry</a></li>
</ul>
</li>
</ul>


<p>D&#8217;autres offres se créent tous les jours. Il est fort à parié qu&#8217;après cette explosion, il va y avoir de la concentration dans les années à venir.</p>

<p>Notons également qu&#8217;une norme Cloud est en train de voir le jour : la norme Open Data Center.</p>

<h2>Conclusion</h2>

<p>On voit que les possibilités du Cloud sont immenses et que les fournisseurs et leurs services sont nombreux. Aussi il me parait important avant de se lancer dans n&#8217;importe quel projet Cloud de faire un étude sérieuse et de ne pas promettre à ses clients/décideurs que le Cloud est la réponse à tous leurs problèmes.</p>
]]></content>
  </entry>
  
</feed>

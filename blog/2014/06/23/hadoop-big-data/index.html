
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Introduction &agrave; Hadoop - Le Blog d'Eric Vidal</title>
  <meta name="author" content="Eric Vidal">

  
  <meta name="description" content="">
  

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="http://fonts.googleapis.com/css?family=Allan:bold" rel="stylesheet" type="text/css">
  <link href="http://fonts.googleapis.com/css?family=Cardo" rel="stylesheet" type="text/css">

  
  <link rel="canonical" href="http://evidal.github.io/blog/2014/06/23/hadoop-big-data">
  <link href="/favicon.png" rel="icon">
  
  <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.no-icons.min.css" rel="stylesheet">
  <link href="//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css" rel="stylesheet">
  <link href="/stylesheets/elusive-webfont.css" rel="stylesheet">

  
  <link href="/stylesheets/syntax/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/custom.css" media="screen, projection" rel="stylesheet" type="text/css">

  <script src="/javascripts/libs/jquery.js"></script>
  <script src="/javascripts/libs/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/bootstrap.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Le Blog d'Eric Vidal" type="application/atom+xml">
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-28850873-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <div class="container-narrow">  
	  <div class="container">
	  	<div class="header">
  <div class="container">
    <img src="/images/coffee-cup-48.png" class="headerct">
    <a class="headerct" href="/">Le Blog d'Eric Vidal</a>
  </div>
  <nav role="navigation"><div class="navbar navbar-inverse container">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>

      <!-- <a class="brand" href="/">Le Blog d'Eric Vidal</a> -->

      <div class="nav-collapse">
        <ul class="nav">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/cv">CV</a></li>
</ul>


        <ul class="nav pull-right" data-subscription="rss">
          <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS"><i class="icon-rss"></i></a></li>
          
        </ul>

        
          <form class="pull-right navbar-search" action="http://google.com/search" method="get">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:www.eric-vidal.com" />
              <input class="search-query" type="text" name="q" results="0" placeholder="Search"/>
            </fieldset>
          </form>
        
      </div>
    </div>
  </div>
</div>

      <!-- <div class="">
        <ul class="nav nav-pills pull-right">
          <li class="active"><a href="#">Home</a></li>
          <li><a href="/">Blog</a></li>
          <li><a href="/blog/archives">Archives</a></li>
        </ul>
        <h3 class="muted">
          <img src="/images/coffee-cup-48.png" class="headerct">
          <a class="headerct" href="/">Le Blog d'Eric Vidal</a>
        </h3>
      </div> -->
</nav>
</div>

	    <div class="row">
	      
<div class="span9">

  <article class="hentry" role="article">
    
  <header class="page-header">
    
      <h1 class="entry-title">Introduction &agrave; Hadoop</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-23T00:00:00+02:00" pubdate data-updated="true">23/06/14</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p><a href="http://hadoop.apache.org/">Hadoop</a> est un système permettant de gérer des très gros volumes de données aussi bien au niveau de leur
stockage qu&#8217;au niveau de leur traitement. Pour mettre les choses au clair tout de suite, Hadoop est une solution à oublier en
dessous d&#8217;une grosse dizaine de serveurs. Hadoop est un système taillé pour gérer des centaines voir des milliers de serveurs. Il faut donc dégainer cette solution quand c&#8217;est nécéssaire. Google utilise par exemple ce type de technologie pour gérer les gros
traitements sur son cluster de serveurs. C&#8217;est d&#8217;ailleurs Google qui est à l&#8217;origine des concepts fondateurs d&#8217;Hadoop.</p>

<!--more-->


<p>Hadoop n&#8217;est pas monobloc, c&#8217;est plutot un ensemble de composants spécialisés.</p>

<h1>HDFS</h1>

<p>Hadoop Distributed File System (HDFS) est l&#8217;implémentation open source des concepts introduits par le Google File System.
C&#8217;est un système de fichier ditribué, taillé pour les gros volumes de données. HDFS est capable de gérer des volumes de
plusieurs péta octets. Les blocs de données sont proportionnelles à la volumétrie potentielle et sont fixés par défaut à
64 méga octets.</p>

<p><img src="/images/posts/2014-06-15-hadoop-big-data/hdfsarchitecture.gif" alt="HDFS Architecture" />
(source <a href="http://hadoop.apache.org/docs/r1.2.1/hdfs_design.html">http://hadoop.apache.org/docs/r1.2.1/hdfs_design.html</a>)</p>

<p>Le Namenode est le serveur du cluster Hadoop s&#8217;occupant des méta-données du file system (Nom, réplication, emplacement, etc&hellip;)</p>

<p>Les serveurs de données eux stockent les blocs des fichiers.</p>

<h1>Map Reduce</h1>

<p>Map Reduce est un modèle de programmation permettant de distribuer l&#8217;éxécution d&#8217;une tache sur plusieurs serveurs (e.g. un tri, une
indexation, un calcul, etc.) Le &ldquo;travail&rdquo; de Map Reduce va être de découper, trier et rassembler les données à différents moment de
l&#8217;éxécution d&#8217;une tâche.</p>

<p>On peut schématiser l&#8217;éxection d&#8217;un batch Map Reduce avec le schéma suivant:</p>

<p><img src="/images/posts/2014-06-15-hadoop-big-data/MapReduce.png" alt="HDFS Architecture" /></p>

<ul>
<li>Les données stockées dans des blocs HDFS vont être tronçonnées en InputSplit.

<ul>
<li>e.g. des lignes d&#8217;un fichier de log</li>
</ul>
</li>
<li>Les records readers vont assigner une clé k1 et une valeur v1 pour toute donnée lue.

<ul>
<li>e.g. le numéro de la ligne comme clé, la ligne compléte en valeur</li>
</ul>
</li>
<li>Le fonction de Mapping va lire et transformer cette première entrée en une autre paire clé-valeur (k2, v2).

<ul>
<li>e.g. La ligne de log est analysée, on met en clé le nom d&#8217;un utilisateur et en valeur 1, représentant un login par exemple</li>
</ul>
</li>
<li>La fonction de partition va déterminer en fonction de la clé k2 vers quel Reducer la clé va être routée</li>
<li>La fonction de Shuffle and Sort rassemble par clé k2 toutes les valeurs v2 émises pas les Mappers

<ul>
<li>e.g. On se retrouve à cette étape avec le nom d&#8217;un utilisateur et une liste de 1 correspondant à toutes les occurences de connections</li>
</ul>
</li>
<li>Le Reducer va transformer une clé k2 et sa liste de valeur v2 en une nouvelle clé k3 et une nouvelle valeur v3.

<ul>
<li>e.g. Le reducer va sommer toutes les valeurs pour un utilisateur en comptant toutes les valeurs de la liste. Par exemple evidal c&#8217;est connecté 3 fois.</li>
</ul>
</li>
<li>Le traitement étant terminé, on peut procéder à l&#8217;écriture des fichiers.</li>
</ul>


<p>Implémentez un job Map Reduce pour Hadoop consiste en l&#8217;assemblage de Mapper, Reducer, Reader, Writer, Partionner.</p>

<p>Des implémentations de certaines de ces classes sont déjà fournies pour des tâches simples (e.g. identités).</p>

<p>L&#8217;assemblage se fait via une une classe Java qui va positionner via des setters les éléménts à utiliser.
On livre sur le cluster un jar contenant les classes nécéssaires à l&#8217;éxécution d&#8217;un job.</p>

<p>Pour l&#8217;éxécution, Hadoop va instancier une JVM sur les différents noeuds et éxécuter le job qu&#8217;on a livré.<br/>
En développement, un mode classique (lancé de manière transparente) permet d&#8217;éxécuter un job Map Reduce en dehors d&#8217;un cluster Hadoop.<br/>
Pour les test unitaire, on peut utiliser des outils comme <a href="http://mrunit.apache.org/">MRUnit</a>.</p>

<h1>Hive, Impala, Pig &amp; Oozie</h1>

<p>Map Reduce, c&#8217;est bien mais ça peut devenir un peu fastidieux s&#8217;il faut écrire des jointures. D&#8217;autant plus que ce n&#8217;est pas vraiment passionnant à coder. Des outils de plus haut niveau ont été développés pour travailler plus facilement qu&#8217;avec Map Reduce.</p>

<ul>
<li><a href="http://hive.apache.org/">Hive</a> est un langage très similaire au SQL. Tout d&#8217;abord on mappe les données d&#8217;un fichier pour exposer son contenu comme une table. Une fois que l&#8217;on a déclaré plusieurs tables, on peut écrire des requêtes pour interroger le cluster Hadoop comme un base de données relationnelle. Ca semble trivial, mais il faut toujours penser que ce système est fait pour gérer de très gros volumes de données, pas des volumétries standards.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SELECT stock.product, SUM(orders.purchases)
</span><span class='line'>FROM stock JOIN orders
</span><span class='line'>ON (stock.id = orders.stock_id)
</span><span class='line'>WHERE orders.quarter = 'Q1'
</span><span class='line'>GROUP BY stock.product;</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://pig.apache.org/">Pig</a> est un autre système permettant d&#8217;écrire des jobs Map Reduce de manière plus simple. Pig prend plus la forme d&#8217;un script, on indique quelles données charger et les opérations à faire avec.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>stock = LOAD '/user/fred/stock' AS (id, item);
</span><span class='line'>orders = LOAD '/user/fred/orders' AS (id, cost);
</span><span class='line'>grpd = GROUP orders BY id;
</span><span class='line'>totals = FOREACH grpd GENERATE group,
</span><span class='line'>SUM(orders.cost) AS t;
</span><span class='line'>result = JOIN stock BY id, totals BY group;
</span><span class='line'>DUMP result;</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html">Impala</a> ressemble à Hive du point de vue syntaxique. La grosse différence entre les 2 est qu&#8217;Impala ne va pas générer un job Map Reduce, mais va utiliser d&#8217;autres algorithmes pour éxécuter la requête et donner une réponse très rapidement.</li>
</ul>


<p>Oozie est un système permettant d&#8217;écrire plusieurs tâches qui vont s&#8217;enchainer. Par exemlple commencer par un job Hive, suivi d&#8217;un job Map Reduce classique et enfin d&#8217;un autre job Hive. Cela permet de créer des chaines de traitement plus complexes.</p>

<h1>Distribution</h1>

<p>Si Hadoop est disponible sur le site du projet Apache, des distributions sont également disponibles chez des éditeurs:</p>

<ul>
<li><a href="http://www.cloudera.com/content/cloudera/en/home.html">Cloudera</a></li>
<li><a href="Horton%20Works">Horton Works</a></li>
<li><a href="http://www.mapr.com/">MapR</a></li>
</ul>


<p>Le gros avantage de passer par une distribution commerciale est que l&#8217;on peut acheter du support. Parfois, ces distributions assemblent des versions différentes des composants core pour avoir un fonctionnement plus cohérent.</p>

<p>Enfin, sur leurs sites, des machines virtuelles (e.g. chez <a href="http://www.cloudera.com/content/support/en/downloads/quickstart_vms/cdh-5-0-x.html">Cloudera</a>) sont disponibles pour tester, ce qui est un gros gain de temps.</p>

<h1>Conclusion</h1>

<p>Hadoop n&#8217;est pas la solution que l&#8217;on va sortir à tout bout de champ. Le but est de manipuler de très très gros volumes de données.
C&#8217;est clairement un outil qui va devenir de plus en plus utile avec l&#8217;explosion des données récoltées par les objets connectées ou toutes les traces que nous laissons sur Internet.</p>
</div>


    <footer>
      <p class="meta">
        
  

<span class="byline author vcard">Posted by <span class="fn">Eric Vidal</span></span>

        








  


<time datetime="2014-06-23T00:00:00+02:00" pubdate data-updated="true">23/06/14</time>
        

<span class="categories">
  
    <a class='category' href='/blog/categories/big/'>big</a>, <a class='category' href='/blog/categories/data/'>data</a>
  
</span>


      </p>
      
        <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://evidal.github.io/blog/2014/06/23/hadoop-big-data/" data-via="EricVidalPro" data-counturl="http://evidal.github.io/blog/2014/06/23/hadoop-big-data/" >Tweet</a>
  
  
  
</div>

      
      
      <section>
        <h1>Comments</h1>
        <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
      </section>
      
      <ul class="pager">
        
        <li class="previous"><a class="basic-alignment left"
          href="/blog/2014/05/02/mixit14/" title="Previous Post:
          Mix-it 2014">&laquo; Mix-it 2014</a></li>
        
        <li><a href="/blog/archives">Blog Archives</a></li>
        
        <li class="next"><a class="basic-alignment right" href="/blog/2014/12/23/mooc-machine-learning/"
          title="Next Post: MOOC Machine Learning par Andrew Ng">MOOC Machine Learning par Andrew Ng
          &raquo;</a></li>
        
      </ul>
    </footer>
  </article>
</div>

<aside class="sidebar-nav span3">
  
    <section class="aside" >
	<h4>&Agrave; propos</h4>
	<img src="/images/evidal_200.png" class="picid"> Je suis architecte chez <a href="http://www.sicap.com">Sicap</a>. Passionné par mon métier et les nouvelles technologies, ce blog me sert de bloc-notes pour partager certaines découvertes.
	<ul class="social">
		<li><a title="Twitter" href="http://twitter.com/#!/EricVidalPro"><i class="icon-twitter"></i></a></li>
        <li><a title="Linkedin" href="http://www.linkedin.com/pub/eric-vidal/4/582/99"><i class="icon-linkedin"></i></a></li>
        <li><a title="Viadeo" href="http://www.viadeo.com/fr/profile/eric.vidal"><i class="icon-viadeo"></i></a></li>
        <li><a title="Github" href="https://github.com/evidal"><i class="icon-github"></i></a></li>
        <li><a title="RSS" href="/blog/eric-vidal.rss"><i class="icon-rss"></i></a></li>
    </ul>
</section>	<section class="aside">
	<h4>R&eacute;cemment post&eacute;s</h4>
  <ul id="recent_posts" class="nav nav-list">
    
      <li class="post">
        <a href="/blog/2015/04/08/devoxx/">Devoxx France 2015</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/23/mooc-machine-learning/">MOOC Machine Learning par Andrew Ng</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/23/hadoop-big-data/">Introduction &agrave; Hadoop</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/02/mixit14/">Mix-it 2014</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/03/cordova-phonegap/">Cordova & Phonegap</a>
      </li>
    
  </ul>
</section>
<section class="aside">
	<h4>Tags</h4>
	<div id="cloud">
		
	        <a href="/blog/categories/blog/" rel="1">blog</a>
		
	        <a href="/blog/categories/conf/" rel="7">conf</a>
		
	        <a href="/blog/categories/java/" rel="7">java</a>
		
	        <a href="/blog/categories/cloud/" rel="1">cloud</a>
		
	        <a href="/blog/categories/perf/" rel="3">perf</a>
		
	        <a href="/blog/categories/groovy/" rel="1">groovy</a>
		
	        <a href="/blog/categories/jee/" rel="2">jee</a>
		
	        <a href="/blog/categories/elasticsearch/" rel="3">elasticsearch</a>
		
	        <a href="/blog/categories/html5/" rel="2">html5</a>
		
	        <a href="/blog/categories/javascript/" rel="1">javascript</a>
		
	        <a href="/blog/categories/cryptographie/" rel="1">cryptographie</a>
		
	        <a href="/blog/categories/objets/" rel="1">objets</a>
		
	        <a href="/blog/categories/mobile/" rel="1">mobile</a>
		
	        <a href="/blog/categories/big/" rel="2">big</a>
		
	        <a href="/blog/categories/data/" rel="2">data</a>
		
	</div>
</section>	
  
</aside>


	    </div>
	    <footer role="contentinfo" class="page-footer"><div class="footer">
	<div class="container">
	  Copyright &copy; 2015 - Eric Vidal -
	  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
	</div>
</div>
</footer>
	  </div>	  
  </div>  
  

<script type="text/javascript">
      var disqus_shortname = 'ericvidalblog';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://evidal.github.io/blog/2014/06/23/hadoop-big-data/';
        var disqus_url = 'http://evidal.github.io/blog/2014/06/23/hadoop-big-data/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>


<script type="text/javascript" src="/javascripts/jquery.tagcloud.js"></script>
<script type="text/javascript">
	$.fn.tagcloud.defaults = {
	  size: {start: 10, end: 20, unit: 'pt'},
	  color: {start: '#5C7270', end: '#FF7530'}
	};

	$(function () {
		console.log("coucou")
	  $('#cloud a').tagcloud();
	});
</script>



</body>
</html>
<!--
<script language="javascript">
	$.backstretch("http://unsplash.s3.amazonaws.com/batch%204/jet-sky.jpg");
</script>
-->
<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: elasticsearch | Le Blog d'Eric Vidal]]></title>
  <link href="http://evidal.github.io/blog/categories/elasticsearch/atom.xml" rel="self"/>
  <link href="http://evidal.github.io/"/>
  <updated>2014-01-07T14:13:42+01:00</updated>
  <id>http://evidal.github.io/</id>
  <author>
    <name><![CDATA[Eric Vidal]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Elastic Search en production]]></title>
    <link href="http://evidal.github.io/blog/2013/11/05/elasticsearch-premiere-production/"/>
    <updated>2013-11-05T00:00:00+01:00</updated>
    <id>http://evidal.github.io/blog/2013/11/05/elasticsearch-premiere-production</id>
    <content type="html"><![CDATA[<p>Ça y'est, j'ai mis mon premier cluster Elastic Search en production : plus d'un milliards de documents  et chaque jour environ 500000 nouveaux documents ajoutés. Ça tourne sur 3 nœuds identiques, chacun contient une instance Elastic Search et les applications l'alimentant et l'exploitant.</p>

<p>Avoir plusieurs instances d'un même système facilite la montée en charge car le système supporte les &ldquo;scale out&rdquo; pour absorber plus de données ou plus de charge.</p>

<p>Le paramétrage d'un Elastic Search en production doit être optimisé sous peine d'avoir de gros problèmes. Je recommande fortement le visionnage de ce <a href="http://www.elasticsearch.org/webinars/elasticsearch-pre-flight-checklist/">webinar</a> qui permet d'avoir une idée de tout ce qu'il faut faire (et de comprendre) pour configurer un Elastic Search en production.</p>

<p>Ce qu'il faut retenir:</p>

<ul>
<li>Bien dimensionner la mémoire, 1 Go (le réglage par défaut) n'est pas suffisant</li>
<li>Ne pas allouer plus de 32 Go de Heap Size, le format des pointeurs de la JVM change après cette valeur. Il vaut mieux ajouter un serveur si on est limite au niveau mémoire</li>
<li>Penser à prévoir le double de mémoire physique par rapport au Heap alloué (e.g. si on met 32 Go de Heap, le serveur va en consommer 64 Go physique). Cela est dû à Elastic Search qui utilise massivement le cache du système de fichier.</li>
<li>Prévoir des disques rapides, les &ldquo;disk arrays&rdquo; ne sont pas vraiment utiles.</li>
<li><p>Préparer le système pour que l'utilisateur qui lance le process Elastic Search puisse ouvrir le maximum de fichier.</p>

<ul>
<li>Editer <em>/etc/security/limits.conf</em> pour ajouter
```

<h1>Ensure ElasticSearch can open files and lock memory!</h1>

<p>elasticsearch   soft    nofile          65536
elasticsearch   hard    nofile          65536
elasticsearch   &ndash;       memlock         unlimited
```</p></li>
</ul>
</li>
<li><ul>
<li>Ensuite dans le .bash_profile de l'utilisateur ajouter la ligne</li>
</ul>
</li>
</ul>


<p><code>
ulimit –n 65536
</code></p>

<ul>
<li>Toujours installer la dernière version de Java et d'Elastic Search, de gros porblèmes sont survenus avec des versions pas à jour de Java.</li>
<li>Attention avec le service Wrapper fourni <a href="https://github.com/elasticsearch/elasticsearch-servicewrapper">ici</a>. Son usage est réservé aux personnes payant la licence pour le composant <a href="http://wrapper.tanukisoftware.com/doc/english/download.jsp">Service Wrapper de Tanuki Software</a>.</li>
<li>Dans conf/elasticsearch.yml

<ul>
<li>Décommentez <em>cluster.name</em> et fixez la même valeur sur l'ensemble des serveurs,</li>
<li>Décommentez <em>node.name</em> et fixez une valeur différente pour chaque nœud,</li>
<li>Mettre à jour les chemins <em>path.data</em> et <em>path.logs</em> pour les faire pointer en dehors du repertoire d'installation d'Elastic Search. Cela permet de bien gérer les montées de versions et de créer des partitions adaptées.</li>
<li>Décommentez <em>discovery.zen.ping.multicast.enabled</em> et mettre à <em>false</em></li>
<li>Décommentez <em>discovery.zen.ping.unicast.hosts</em> et mettre la liste des membres du cluster</li>
<li>Fixez <em>gateway.recover_after_nodes</em> au nombre de noeuds du cluster</li>
<li>Fixez <em>discovery.zen.minimum_master_nodes</em> à (nombre de nodes/2)+1</li>
</ul>
</li>
<li>Mettez en variable d'environnement de l'utilisateur la variable <em>ES_HEAP_SIZE</em> et fixez la à la taille coulue (e.g. export ES_HEAP_SIZE=16g)</li>
</ul>


<p>Avec tout ça vous devriez avoir le début d'un cluster qui fonctionne bien.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Combo Logstash, Elastic Search & Kibana, l'arme absolue des logs]]></title>
    <link href="http://evidal.github.io/blog/2013/09/25/elasticsearch-logstash-Kibana/"/>
    <updated>2013-09-25T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2013/09/25/elasticsearch-logstash-Kibana</id>
    <content type="html"><![CDATA[<p>L'exploitation des logs sur les applications complexes est assez compliquée. Les applications que mon entreprise développe sont morcelées en plusieurs
couches: Front-End, Back-Enf, Back-Office, Front-Office, Connecteurs, etc&hellip; Chaque application génère ses lots de logs, qu'ils soient purement techniques
ou bien à but &ldquo;business&rdquo;, dans mon cas des CDR ayant une certaine valeur pour la facturation de nos clients.</p>

<p>Comment avec tous ces logs donner une vision cohérente et syntétique de ce qu'il se passe sur la plateforme ? Comment archiver ces logs efficacement
pour les 5 prochaines années tout en générant des centaines de milliers de logs ?</p>

<p>La réponse est en utilisant le combo <a href="http://www.elasticsearch.org/">Elastic Search</a>, <a href="http://logstash.net/">Logstash</a> et <a href="http://www.elasticsearch.org/overview/kibana/">kibana 3</a>. <a href="http://logstash.net/">Logstash</a> est une sorte de super ETL permettant de spécifier des entrées, des transformations
et des sorties. La configuration est assez simple et en deux temps 3 mouvements on est capable de configurer un ETL capable de lire tous les fichiers
d'un repertoire, de les parser intelligemment et de les injecter dans un index <a href="http://www.elasticsearch.org/">Elastic Search</a>. Globalement pour
une ligne de log, on va se retrouver avec un document Elastic Search. La ligne de texte originale est conservée, et plusieurs champs sont créés,
correspondant aux directives que vous configurez dans le fichier de conf Logstash.</p>

<p>Dans mon cas j'ai utilisé une entrée de type file permettant d'explorer un repertoire et tout ses sous-repertoires. J'ai chainé cette entrée avec un
filtre grok qui permet de parser la ligne de log. J'ai d'ailleurs utilisé <a href="http://grokdebug.herokuapp.com/">Grok Debugger</a> un outil permettant de tester
des directives sur des logs réels. Si les patterns préprogrammés de GRok sont insuffisant, on peut facielement définir des expressions régulières
permettant d'étendre les possibilités de Grok. Enfin les logs sont indéxés par Elastic Search, on peut choisir d'utiliser l'Elastic Search embarqué
dans Logstash ou de pointer vers un Elastic Search distant (la solution que j'ai choisi).</p>

<p>On va configurer Elastic Search pour créer un index par mois (ou par jour pour les très gros producteurs de logs). Cela permet de supprimer les documents par lot le moment venu sans &ldquo;casser&rdquo; les index Elastic Search existant. <a href="http://www.elasticsearch.org/">Elastic Search</a> de par son design permet un accès ultra-rapide à n'importe quelle ligne de log avec la puissance de son module de requêtage et de filtrage.</p>

<p>Enfin <a href="http://www.elasticsearch.org/overview/kibana/">kibana 3</a> (récemment intégré à Elastic Search) permet d'avoir une visualisation des données de log
et de composer des &ldquo;Dashboards&rdquo; super complet. Par exemple, j'ai réalisé ce dashboard très facilement à partir des logs de nos applications.</p>

<p><img src="/images/posts/2013-09-25-elasticsearch-logstash-Kibana/kibana.png" alt="Dashboard Kibana MMG" /></p>

<p>Et voilà ! On quelque chose de complet et complétement présentable très rapidement. Le temps de découvrir Kibana et de comprendre comment cela
fonctionnait, j'ai mis 1 heure. Et tout est connecté, c'est à dire qu'on peut modifier les dates en temps réel (zoomer, dé-zoomer, passer en mode temps-réel, etc&hellip;) et tous les graphes se mettent à jour instantanément. C'est très bluffant.</p>

<p>Bref je recommande vivement l'utilisation de ce combo qu'on peut considérer comme l'arme absolue pour la gestion des logs d'applications.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elastic Search]]></title>
    <link href="http://evidal.github.io/blog/2012/10/18/elastic-search/"/>
    <updated>2012-10-18T00:00:00+02:00</updated>
    <id>http://evidal.github.io/blog/2012/10/18/elastic-search</id>
    <content type="html"><![CDATA[<p>Elastic Search est un moteur de recherche basé sur Lucene expérimenté par la société
dans laquelle je travaille depuis un certain temps. Ce moteur était présenté
dans le cadre du Lyon JUG par <a href="http://dev.david.pilato.fr/">David Pilato</a> et <a href="https://twitter.com/tlrx">Tanguy Leroux</a>.</p>

<p>L'interview pre-JUG par les Duchess est disponible <a href="http://www.duchess-france.org/rencontre-avec-david-pilato-sur-elastic-search/">ici</a>.
La présentation elle même est disponible <a href="http://t.co/piqUOkTE">ici</a>.</p>

<p>Je ne vais pas réexpliquer le fonctionnement d'Elastic Search car de nombreux articles le font déjà (et notamment la présentation de David Pilato).
De notre coté nous avons sélectionner Elastic Serach pour plusierus fonctionnalités importantes pour nous:</p>

<ul>
<li>Nos logicielles sont déployés sur des clusters pour avoir un fonctionnement Actif-Actif. C'est une des fonctionnalités de base d'Elastic Search.</li>
<li>Nous manipulons des données très volumineuses en terme de nombre (plusieurs dizaines, voir centaines de millions). Elastic Serach est &ldquo;taillé&rdquo; pour ce volume.</li>
<li>La navigation par &ldquo;Facet&rdquo; qui nous est nécéssaire</li>
</ul>


<p>Cependant nous en sommes encore au stade de l'étude et nous n'avons pas encore de vrai déploiement utilisant cette technologie.</p>

<p>Voilà quelques points importants que j'ai noté pour mémoire:</p>

<ul>
<li>Sécurisation,

<ul>
<li>pour l’instant Elastic Search n’est pas sécurisé. Il est possible qu’il le devienne mais pas dans les toutes prochaines versions.</li>
<li>1ère stratégie : mettre un apache devant et « jouer » avec les règles d'un firewall (DMZ)
<strong> ajouter une couche http authent pour l'accès
</strong> utiliser des filtres pour restreindre l’utilisation de certaines commande (comme DELETE, PUT)
** en séparant les index, on peut spécifier des chemins d’accès à des données et gérer des profils</li>
<li>2ème stratégie, utiliser le plugin suivant <a href="https://github.com/sonian/elasticsearch-jetty">https://github.com/sonian/elasticsearch-jetty</a> (solution recommandé uniquement par 1 des speakers)</li>
</ul>
</li>
<li>Cluster et déploiement

<ul>
<li>Les préconisation de déploiement sont de 1 shard par serveur (1 shard = 1 instance de Lucene) + 1 replica</li>
<li>/!\ on ne peut pas changer le nombre de shards une fois qu’un index est crée</li>
<li>Les intervenants recommandent de bien dimensionner son cluster dès le départ, rajouter un nouveau membre au cluster est assez lourd en terme de consommation sur des indexes volumineux</li>
<li>Il est préférable d’effectuer les montées de version à froid (même si des procédures à chaud existent)</li>
<li>D’après le concepteur d’Elastic Search si une requête met plus de 100ms, c’est que la plate-forme est sous dimmensionné.</li>
</ul>
</li>
<li>Il existe une JDBC River qui permet automatiquement d’indexer une table au fil de l’eau

<ul>
<li><a href="https://github.com/jprante/elasticsearch-river-jdbc">https://github.com/jprante/elasticsearch-river-jdbc</a></li>
</ul>
</li>
<li>Un projet d’indexation de Log existe déjà

<ul>
<li><a href="http://logstash.net/">http://logstash.net/</a></li>
</ul>
</li>
<li>Déploiement de références

<ul>
<li>Des déploiements existent avec 25 noeuds indexant plus d’1 milliard de documents</li>
<li>Le premier intervenant (David Pilato) a travaillé sur un projet indexant 500.000 documents des douanes françaises. Le projet tournait sur 3 serveurs low end (CPU 2 cores, mémoire 4GB)</li>
<li>Le deuxième (Tanguy Leroux) a travaillé pour un assureur pour indexer 20.000.000 documents (chaque document était l’équivalent d’une page word). Le projet tournait sur 4 serveurs low end (CPU 2 cores, mémoire 4GB)</li>
</ul>
</li>
<li>Utiliser Elastic Search comme un entrepot de données

<ul>
<li>le créateur le déconseille pour l'instant mais ce sera peut-être possible à l'avenir.</li>
<li>Un des intervenant a indiqué qu'il connaissait un projet utilisant Elastic Search comme base de données principale. Mais dans ce cas il fallait faire une croix sur les transactions et autres fonctionnalités d'une base de données.</li>
</ul>
</li>
</ul>


<p>Session très intéréssante et speakers disponibles pour répondre aux questions !</p>

<p>Merci le Lyon JUG.</p>
]]></content>
  </entry>
  
</feed>
